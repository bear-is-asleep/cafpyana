{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## In this example, we will study output data frame from pandora.py configuration\n",
    "#### 1. Opening each data frame and check structure\n",
    "#### 2. Collect POT and scale factor to the target POT\n",
    "#### 3. Merge evtdf and mcnudf for further study\n",
    "#### 4. Draw some plots for each slice and for each pfp\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import uproot as uproot\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib import ticker\n",
    "from matplotlib.ticker import (AutoMinorLocator, MultipleLocator)\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# Add the head direcoty to sys.path\n",
    "workspace_root = os.getcwd()  \n",
    "sys.path.insert(0, workspace_root + \"/../../\")\n",
    "\n",
    "# import this repo's classes\n",
    "import pyanalib.pandas_helpers as ph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Open each df\n",
    "venv_path = os.getenv(\"PATH\")\n",
    "input_df_path = \"/exp/sbnd/data/users/sungbino/sbnd_samples/cafpyana_outputs/cohpi_df_mcweight_test.df\"\n",
    "with pd.HDFStore(input_df_path) as store:\n",
    "    print(store.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohpidf = pd.read_hdf(input_df_path, key='cohpi')\n",
    "hdrdf = pd.read_hdf(input_df_path, key='hdr')\n",
    "mcnuwgtdf = pd.read_hdf(input_df_path, key='mcnuwgt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1.1 Check evtdf structure\n",
    "cohpidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1.2 Check hdrdf structure\n",
    "hdrdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1.3 Check mcnudf structure\n",
    "mcnuwgtdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcnuwgtdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Collect POT and scale factor to the target POT\n",
    "this_pot = sum(hdrdf.pot)\n",
    "print(this_pot)\n",
    "target_POT = 3.0e18\n",
    "POT_scale = target_POT / this_pot\n",
    "print(POT_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohpidf.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohpidf.rec.slc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Merge evtdf and mcnudf\n",
    "#### 1) Merging is based on matching between slc.tmatch.idx of evtdf and rec.mc.nu..index of mcnudf.\n",
    "####    For each entry (readout window), there could be multiple truth neutrino interactions and reconstructed slices\n",
    "####    We want to match each truth neutrion interaction to a corresponding slice\n",
    "\n",
    "matchdf = ph.multicol_merge(cohpidf.reset_index(), mcnuwgtdf.reset_index(),\n",
    "                            left_on=[(\"entry\", \"\",\"\"), (\"rec\", \"slc\",\"tmatch\", \"idx\")],\n",
    "                            right_on=[(\"entry\", \"\",\"\"), (\"rec.mc.nu..index\", \"\",\"\")], \n",
    "                            how=\"left\") ## -- save all sllices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Draw plots\n",
    "#### 4.1) Make dataframe of nu.E for each rec.slc..index (nuE_per_slc) and for each rec.slc.reco.pfp..index (nuE_per_pfp)\n",
    "nuE_col = ('E', '', '', '')\n",
    "nuE_per_slc = matchdf.groupby([('entry'), ('rec.slc..index')])[[nuE_col]].first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nuE_per_slc)\n",
    "print(\"len(nuE_per_slc) = %d\" %len(nuE_per_slc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 4.2) Draw a plot of nu.E for each slc\n",
    "plt.hist(nuE_per_slc.E, bins=np.linspace(0., 6., 71), histtype=\"step\", label=[\"all\"])\n",
    "plt.xlabel(\"Neutrino Energy (GeV)\")\n",
    "plt.ylabel(f\"Neutrinos (POT = {this_pot:.2e})\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 4.4) Draw a plot of nu.E for each slc with POT scaling\n",
    "plt.hist(nuE_per_slc.E, bins=np.linspace(0., 6., 71), weights=[np.ones_like(data) * POT_scale for data in nuE_per_slc.E], histtype=\"step\", label=[\"all\"])\n",
    "plt.xlabel(\"Neutrino Energy (GeV)\")\n",
    "plt.ylabel(f\"Neutrinos (POT = {target_POT:.2e})\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 4.5) Draw nu score distribution per slc\n",
    "nu_score_col = ('rec', 'slc', 'nu_score', '')\n",
    "nu_score_per_slc = matchdf.groupby([('entry'), ('rec.slc..index')])[[nu_score_col]].first()\n",
    "plt.hist(nu_score_per_slc.rec.slc.nu_score, bins=np.linspace(0., 1., 101), weights=[np.ones_like(data) * POT_scale for data in nu_score_per_slc.rec.slc.nu_score], histtype=\"step\", label=[\"all\"])\n",
    "plt.xlabel(\"Neutrion Score\")\n",
    "plt.ylabel(f\"Neutrinos (POT = {target_POT:.2e})\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_py39_cafpyana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
