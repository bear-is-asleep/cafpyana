{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wiener SBND Closure Test for 1mu1p Measurement Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib as mpl\n",
    "from os import path\n",
    "import sys\n",
    "import uproot\n",
    "\n",
    "from wienersvd import *\n",
    "from unfolding_inputs import *\n",
    "\n",
    "# import dunestyle.matplotlib as dunestyle\n",
    "plt.style.use(\"presentation.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig = False\n",
    "save_fig_dir = \"./plots/wiener_svd/1mu1p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = mpl.cm.viridis\n",
    "norm = mpl.colors.Normalize(vmin=0.0, vmax=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_split(file):\n",
    "    this_split_df = pd.read_hdf(file, key=\"split\")\n",
    "    this_n_split = this_split_df.n_split.iloc[0]\n",
    "    return this_n_split\n",
    "\n",
    "def print_keys(file):\n",
    "    with pd.HDFStore(file, mode='r') as store:\n",
    "        keys = store.keys()       # list of all keys in the file\n",
    "        print(\"Keys:\", keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dfs(file, keys2load):\n",
    "    out_df_dict = {}\n",
    "    this_n_keys = get_n_split(file)\n",
    "    n_concat = min(n_max_concat, this_n_keys)\n",
    "    for key in keys2load:\n",
    "        dfs = []  # collect all splits for this key\n",
    "        for i in range(n_concat):\n",
    "            this_df = pd.read_hdf(file, key=f\"{key}_{i}\")\n",
    "            dfs.append(this_df)\n",
    "        out_df_dict[key] = pd.concat(dfs, ignore_index=False)\n",
    "\n",
    "    return out_df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- MC study\n",
    "mc_file = \"/exp/sbnd/data/users/munjung/xsec/2025B/MCP_gump_new.df\"\n",
    "mc_split_df = pd.read_hdf(mc_file, key=\"split\")\n",
    "mc_n_split = get_n_split(mc_file)\n",
    "print(\"mc_n_split: %d\" %(mc_n_split))\n",
    "print_keys(mc_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max_concat = 2\n",
    "\n",
    "mc_keys2load = ['evt', 'hdr', 'mcnuwgtslim']\n",
    "mc_dfs = load_dfs(mc_file, mc_keys2load)\n",
    "\n",
    "mc_evt_df = mc_dfs['evt']\n",
    "mc_hdr_df = mc_dfs['hdr']\n",
    "mc_nu_df = mc_dfs['mcnuwgtslim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move to makedf.py\n",
    "# genie multisims\n",
    "genie_knobs = ['GENIEReWeight_SBN_v1_multisim_ZExpAVariationResponse',\n",
    "               'GENIEReWeight_SBN_v1_multisim_CCRESVariationResponse',\n",
    "               'GENIEReWeight_SBN_v1_multisim_NCRESVariationResponse',\n",
    "               'GENIEReWeight_SBN_v1_multisim_DISBYVariationResponse',\n",
    "               'GENIEReWeight_SBN_v1_multisim_FSI_pi_VariationResponse',\n",
    "               'GENIEReWeight_SBN_v1_multisim_FSI_N_VariationResponse',\n",
    "               'GENIEReWeight_SBN_v1_multisim_NCELVariationResponse']\n",
    "\n",
    "for uidx in range(100):\n",
    "    for kidx, knob in enumerate(genie_knobs):\n",
    "        if kidx == 0:\n",
    "            mc_evt_df[(\"GENIE\", \"univ_{}\".format(uidx), \"\", \"\", \"\", \"\", \"\", \"\")] = mc_evt_df[(knob, \"univ_{}\".format(uidx), \"\", \"\", \"\", \"\", \"\", \"\")]\n",
    "            mc_nu_df[(\"GENIE\", \"univ_{}\".format(uidx), \"\")] = mc_nu_df[(knob, \"univ_{}\".format(uidx), \"\")]\n",
    "        else:\n",
    "            mc_evt_df[(\"GENIE\", \"univ_{}\".format(uidx), \"\", \"\", \"\", \"\", \"\", \"\")] *= mc_evt_df[(knob, \"univ_{}\".format(uidx), \"\", \"\", \"\", \"\", \"\", \"\")]\n",
    "            mc_nu_df[(\"GENIE\", \"univ_{}\".format(uidx), \"\")] *= mc_nu_df[(knob, \"univ_{}\".format(uidx), \"\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## total pot\n",
    "mc_tot_pot = mc_hdr_df['pot'].sum()\n",
    "print(\"mc_tot_pot: %.3e\" %(mc_tot_pot))\n",
    "\n",
    "target_pot = 1e20\n",
    "mc_pot_scale = target_pot / mc_tot_pot\n",
    "print(\"mc_pot_scale: %.3e\" %(mc_pot_scale))\n",
    "mc_pot_scale = 1.\n",
    "\n",
    "mc_evt_df[\"pot_weight\"] = mc_pot_scale * np.ones(len(mc_evt_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: z-dependence?\n",
    "# flux file, units: /m^2/10^6 POT \n",
    "# 50 MeV bins\n",
    "fluxfile = \"/exp/sbnd/data/users/munjung/flux/sbnd_original_flux.root\"\n",
    "flux = uproot.open(fluxfile)\n",
    "print(flux.keys())\n",
    "\n",
    "# numu flux\n",
    "numu_flux = flux[\"flux_sbnd_numu\"].to_numpy()\n",
    "bin_edges = numu_flux[1]\n",
    "flux_vals = numu_flux[0]\n",
    "\n",
    "plt.hist(bin_edges[:-1], bins=bin_edges, weights=flux_vals, histtype=\"step\")\n",
    "plt.xlabel(\"E [GeV]\")\n",
    "plt.ylabel(\"Flux [/m$^{2}$/10$^{6}$ POT]\")\n",
    "plt.title(\"SBND $\\\\nu_\\\\mu$ Flux\")\n",
    "plt.show()\n",
    "\n",
    "# get integrated flux\n",
    "integrated_flux = flux_vals.sum()\n",
    "integrated_flux /= 1e4 # to cm2\n",
    "integrated_flux = integrated_flux * mc_tot_pot / 1e6 # POT\n",
    "print(\"Integrated flux: %.3e\" % integrated_flux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 1.3836  #g/cm3, liquid Ar density\n",
    "N_A = 6.02214076e23 # Avogadroâ€™s number\n",
    "M_Ar = 39.95 # g, molar mass of argon\n",
    "V_sbnd = 2 * 360 * 175 * 440 # cm3, the active volume of the detector # TODO: get exact value\n",
    "NTargets = rho * V_sbnd * N_A / M_Ar\n",
    "print(\"# of targets: \", NTargets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to 1 for event rates\n",
    "xsec_unit = 1 / (integrated_flux * NTargets)\n",
    "\n",
    "xsec_unit = 1\n",
    "print(\"xsec unit: \", xsec_unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InFV(data): # cm\n",
    "    xmin = -190.\n",
    "    ymin = -190.\n",
    "    zmin = 10.\n",
    "    xmax = 190.\n",
    "    ymax =  190.\n",
    "    zmax =  450.\n",
    "    return (np.abs(data.x) > 10) & (np.abs(data.x) < 190) & (data.y > ymin) & (data.y < ymax) & (data.z > zmin) & (data.z < zmax)\n",
    "\n",
    "\n",
    "def IsNu(df):\n",
    "    return ~df.pdg.isna()\n",
    "\n",
    "\n",
    "def Signal(df): # definition                                                                                                                                                                                                                                                                         \n",
    "    is_fv = InFV(df.position)\n",
    "    is_1mu1p0pi = (df.nmu_27MeV == 1) & (df.npi_30MeV == 0) & (df.np_50MeV == 1) & (df.np_20MeV == 1) & (df.npi0 == 0) & (df.mu.genE > 0.25)\n",
    "    return is_fv & is_1mu1p0pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_int_category(df):\n",
    "    is_notnu = ~IsNu(df)\n",
    "    is_nu_outfv = IsNu(df) & ~InFV(df.position)\n",
    "    is_signal = Signal(df)\n",
    "    is_other_nu_infv = IsNu(df) & InFV(df.position) & ~Signal(df)\n",
    "\n",
    "    nuint_categ = pd.Series(8, index=df.index)\n",
    "    nuint_categ[is_notnu] = -1  # not nu\n",
    "    nuint_categ[is_nu_outfv] = 0  # nu out of FV\n",
    "    nuint_categ[is_signal] = 1    # nu in FV, signal\n",
    "    nuint_categ[is_other_nu_infv] = 2  # nu in FV, not signal\n",
    "\n",
    "    return nuint_categ\n",
    "\n",
    "\n",
    "# signal need to come first for below code to work\n",
    "mode_list = [1, 2, 0, -1]\n",
    "mode_labels = [\"Signal\", \"Non-sig. FV Nu\", \"Non FV Nu\", \"Not Nu\"]\n",
    "colors = ['#d62728',  # Red            \n",
    "          '#1f77b4',  # Blue\n",
    "          '#ff7f0e',\n",
    "          '#7f7f7f']  # Gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ccqe selection\n",
    "\n",
    "# in FV\n",
    "print(InFV(mc_evt_df.slc.vertex).value_counts())\n",
    "mc_evt_df = mc_evt_df[InFV(mc_evt_df.slc.vertex)]\n",
    "\n",
    "# mu length cut\n",
    "mc_evt_df = mc_evt_df[mc_evt_df.mu.pfp.trk.len > 50]\n",
    "\n",
    "# mu chi2 cut \n",
    "mc_evt_df = mc_evt_df[(mc_evt_df.mu.pfp.trk.chi2pid.I2.chi2_muon > 0) & (mc_evt_df.mu.pfp.trk.chi2pid.I2.chi2_muon < 25) & (mc_evt_df.mu.pfp.trk.chi2pid.I2.chi2_proton > 100)]\n",
    "mc_evt_df = mc_evt_df[(mc_evt_df.p.pfp.trk.chi2pid.I2.chi2_muon > 0) & (mc_evt_df.p.pfp.trk.chi2pid.I2.chi2_muon < 90)]\n",
    "\n",
    "# 1p0pi\n",
    "twoprong_cut = (np.isnan(mc_evt_df.other_shw_length) & np.isnan(mc_evt_df.other_trk_length))\n",
    "mc_evt_df = mc_evt_df[twoprong_cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move this to makedf.py\n",
    "mc_evt_df.loc[:, (\"mu\",\"pfp\",\"trk\",\"truth\",\"p\",\"totp\",\"\",\"\")] = np.sqrt(mc_evt_df.mu.pfp.trk.truth.p.genp.x**2 + mc_evt_df.mu.pfp.trk.truth.p.genp.y**2 + mc_evt_df.mu.pfp.trk.truth.p.genp.z**2)\n",
    "mc_nu_df.loc[:, ('mu','totp','')] = np.sqrt(mc_nu_df.mu.genp.x**2 + mc_nu_df.mu.genp.y**2 + mc_nu_df.mu.genp.z**2)\n",
    "\n",
    "mc_evt_df.loc[:, (\"mu\",\"pfp\",\"trk\",\"truth\",\"p\",\"dir\",\"x\",\"\")] = mc_evt_df.mu.pfp.trk.truth.p.genp.x/mc_evt_df.mu.pfp.trk.truth.p.totp\n",
    "mc_evt_df.loc[:, (\"mu\",\"pfp\",\"trk\",\"truth\",\"p\",\"dir\",\"y\",\"\")] = mc_evt_df.mu.pfp.trk.truth.p.genp.y/mc_evt_df.mu.pfp.trk.truth.p.totp\n",
    "mc_evt_df.loc[:, (\"mu\",\"pfp\",\"trk\",\"truth\",\"p\",\"dir\",\"z\",\"\")] = mc_evt_df.mu.pfp.trk.truth.p.genp.z/mc_evt_df.mu.pfp.trk.truth.p.totp\n",
    "\n",
    "mc_nu_df.loc[:, (\"mu\",\"dir\",\"x\")] = mc_nu_df.mu.genp.x/mc_nu_df.mu.totp\n",
    "mc_nu_df.loc[:, (\"mu\",\"dir\",\"y\")] = mc_nu_df.mu.genp.y/mc_nu_df.mu.totp\n",
    "mc_nu_df.loc[:, (\"mu\",\"dir\",\"z\")] = mc_nu_df.mu.genp.z/mc_nu_df.mu.totp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify events into categories\n",
    "mc_evt_df.loc[:,'nuint_categ'] = get_int_category(mc_evt_df)\n",
    "mc_nu_df.loc[:,'nuint_categ'] = get_int_category(mc_nu_df)\n",
    "\n",
    "print(mc_evt_df.nuint_categ.value_counts())\n",
    "print(mc_nu_df.nuint_categ.value_counts()) # won't have -1 because nudf is all nu events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closure test \n",
    "- use MC signal as fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# muon momentum\n",
    "var_save_name = \"muon-p\"\n",
    "\n",
    "var_labels = [r\"$\\mathrm{P_\\mu~[GeV/c]}$\", \n",
    "              r\"$\\mathrm{P_\\mu^{reco.}~[GeV/c]}$\",  # reco\n",
    "              r\"$\\mathrm{P_\\mu^{true}~[GeV/c]}$\"]  # true\n",
    "\n",
    "bins = np.linspace(0.2, 2, 6)\n",
    "\n",
    "var_evt_reco_col = ('mu', 'pfp', 'trk', 'P', 'p_muon', '', '', '')\n",
    "var_evt_truth_col = ('mu', 'pfp', 'trk', 'truth', 'p', 'totp', '', '')\n",
    "var_nu_col = ('mu', 'totp', '')\n",
    "\n",
    "# # muon dir z\n",
    "# var_save_name = \"muon-dir_z\"\n",
    "\n",
    "# var_labels = [r\"$\\mathrm{cos(\\theta_\\mu)}$\",\n",
    "#               r\"$\\mathrm{cos(\\theta_\\mu^{reco.})}$\",\n",
    "#               r\"$\\mathrm{cos(\\theta_\\mu^{true})}$\"]\n",
    "\n",
    "# bins = np.linspace(-1, 1, 6)\n",
    "\n",
    "# var_evt_reco_col = ('mu', 'pfp', 'trk', 'dir', 'z', '', '', '')\n",
    "# var_evt_truth_col = ('mu', 'pfp', 'trk', 'truth', 'p', 'dir', 'z', '')\n",
    "# var_nu_col = ('mu', 'dir', 'z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.clip is for including underflow events into the first bin and overflow evetns into the last bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total MC reco muon momentum: for fake data\n",
    "eps = 1e-8\n",
    "var_total_mc = mc_evt_df[var_evt_reco_col]\n",
    "var_total_mc = np.clip(var_total_mc, bins[0], bins[-1] - eps)\n",
    "\n",
    "# mc_evt_df divided into mode for subtraction from data in futre\n",
    "# first item in list is the signal\n",
    "mc_evt_df_divided = [mc_evt_df[mc_evt_df.nuint_categ == mode]for mode in mode_list]\n",
    "\n",
    "# Reco muon momentum for each 'nuint_categ' for stack plot and subtraction from the fake data\n",
    "var_per_nuint_categ_mc = [mc_evt_df[mc_evt_df.nuint_categ == mode][var_evt_reco_col]for mode in mode_list]\n",
    "var_per_nuint_categ_mc = [s.clip(bins[0], bins[-1] - eps) for s in var_per_nuint_categ_mc]\n",
    "weights_per_categ = [mc_evt_df.loc[mc_evt_df.nuint_categ == mode, 'pot_weight'] for mode in mode_list]\n",
    "\n",
    "# for response matrix\n",
    "# Signal event's reco muon momentum after the event selection\n",
    "var_signal = mc_evt_df[mc_evt_df.nuint_categ == 1][var_evt_reco_col]\n",
    "var_signal = np.clip(var_signal, bins[0], bins[-1] - eps)\n",
    "weight_signal = mc_evt_df.loc[mc_evt_df.nuint_categ == 1, 'pot_weight']\n",
    "\n",
    "# Signal event's true muon momentum after the event selection\n",
    "true_var_signal_sel = mc_evt_df[mc_evt_df.nuint_categ == 1][var_evt_truth_col]\n",
    "true_var_signal_sel = np.clip(true_var_signal_sel, bins[0], bins[-1] - eps)\n",
    "weight_true_signal = mc_evt_df.loc[mc_evt_df.nuint_categ == 1, 'pot_weight']\n",
    "\n",
    "# for efficiency vector\n",
    "# Signal event's true muon momentum without event selection\n",
    "var_truth_signal = mc_nu_df[mc_nu_df.nuint_categ == 1][var_nu_col]\n",
    "var_truth_signal = np.clip(var_truth_signal, bins[0], bins[-1] - eps)\n",
    "weight_truth_signal = np.full_like(var_truth_signal, mc_pot_scale, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw true (before event selection) and reco (after event selection) muon momentum distributions of signal events.\n",
    "Print entries for double check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_signal, _, _ = plt.hist(var_truth_signal, bins=bins, weights=weight_truth_signal, histtype=\"step\", label=\"True Signal\")\n",
    "reco_signal_sel, _, _ = plt.hist(var_signal, bins=bins, weights=weight_signal, histtype=\"step\", label=\"Reco Selected Signal\")\n",
    "true_signal_sel, _, _ = plt.hist(true_var_signal_sel, bins=bins, weights=weight_signal, histtype=\"step\", label=\"True Selected Signal\")\n",
    "print(true_signal)\n",
    "print(reco_signal_sel)\n",
    "print(true_signal_sel)\n",
    "plt.legend()\n",
    "plt.ylabel(\"Events\")\n",
    "plt.xlim(bins[0], bins[-1])\n",
    "plt.xlabel(var_labels[0])\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-sel_event_rates.pdf\".format(save_fig_dir, var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "mc_stack, bins, _ = plt.hist(var_per_nuint_categ_mc,\n",
    "                            bins=bins,\n",
    "                            weights=weights_per_categ,\n",
    "                            stacked=True,\n",
    "                            color=colors,\n",
    "                            label=mode_labels,\n",
    "                            edgecolor='none',\n",
    "                            linewidth=0,\n",
    "                            density=False,\n",
    "                            histtype='stepfilled')\n",
    "\n",
    "totmc, bin_edges = np.histogram(var_total_mc, bins=bins, weights=mc_evt_df.pot_weight)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# use MC as fake data for closure test\n",
    "fake_data = totmc\n",
    "fake_data_err = np.sqrt(totmc)\n",
    "# plt.step(bin_edges[:-1], fake_data, where='post', label=\"Data\")  # line\n",
    "plt.errorbar(bin_centers, fake_data, yerr=fake_data_err, fmt='o', color='black')  # error bars\n",
    "\n",
    "accum_sum = [np.sum(data) for data in mc_stack]\n",
    "accum_sum = [0.] + accum_sum\n",
    "total_sum = accum_sum[-1]\n",
    "individual_sums = [accum_sum[i + 1] - accum_sum[i] for i in range(len(accum_sum) - 1)]\n",
    "fractions = [(count / total_sum) * 100 for count in individual_sums]\n",
    "legend_labels = [f\"{label} ({frac:.1f}%)\" for label, frac in zip(mode_labels[::-1], fractions[::-1])]\n",
    "legend_labels.append(\"Fake Data\")\n",
    "plt.legend(legend_labels, loc='upper left', fontsize=10, frameon=False, ncol=3, bbox_to_anchor=(0.05, 0.98))\n",
    "\n",
    "plt.xlim(bins[0], bins[-1])\n",
    "plt.xlabel(var_labels[1])\n",
    "plt.ylim(0., 1.2 * fake_data.max())\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-fake_data.pdf\".format(save_fig_dir, var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# response matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_2d = bins# = [np.array([0.2, 2]), np.array([0.2, 2])] # commented out lines for 1 bin MC closure test\n",
    "reco_vs_true = get_smear_matrix(true_var_signal_sel, var_signal, bins_2d, var_labels=var_labels)\n",
    "eff = get_eff(reco_vs_true, true_signal)\n",
    "print(\"eff\")\n",
    "print(eff)\n",
    "Response = get_response_matrix(reco_vs_true, eff, bins, var_labels=var_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_centers = (bins[:-1] + bins[1:])/2\n",
    "univ_events = []\n",
    "\n",
    "# get background subtracted event rate for fake data\n",
    "nominal_event = fake_data\n",
    "for this_mc_evt_df in mc_evt_df_divided[1:]:  # first item is the signal\n",
    "    this_var = this_mc_evt_df[var_evt_reco_col]\n",
    "    this_var = np.clip(this_var, bins[0], bins[-1] - eps)\n",
    "    this_n, bins = np.histogram(this_var, bins=bins)\n",
    "    nominal_event = nominal_event - this_n\n",
    "\n",
    "# get syst universes on background subtracted event rate for fake data\n",
    "n_univ_flux = 1000\n",
    "for uidx in range(n_univ_flux):\n",
    "    this_signal = fake_data # before subtraction\n",
    "    for this_mc_evt_df in mc_evt_df_divided[1:]: # first item is the signal\n",
    "        weights = this_mc_evt_df[\"Flux\"][\"univ_{}\".format(uidx)].copy()\n",
    "        weights[np.isnan(weights)] = 1 ## IMPORTANT: make nan weights to 1. to ignore them\n",
    "        this_var = this_mc_evt_df[var_evt_reco_col]\n",
    "        this_var = np.clip(this_var, bins[0], bins[-1] - eps)\n",
    "        this_n, bins = np.histogram(this_var, bins=bins, weights=weights)\n",
    "        this_signal = this_signal - this_n # a subtracted hitogram for a multiverse\n",
    "    univ_events.append(this_signal)\n",
    "\n",
    "for univ_event in univ_events:\n",
    "    plt.step(bin_edges, np.append(univ_event, univ_event[-1]), where='post', color=\"gray\")\n",
    "    plt.xlim(bins[0], bins[-1])\n",
    "    plt.xlabel(var_labels[0])\n",
    "    plt.ylabel(\"Events\")\n",
    "\n",
    "plt.step(bin_edges, np.append(nominal_event, nominal_event[-1]), where='post', color=\"black\", label=\"Nominal\")\n",
    "\n",
    "plt.title(\"Background Subtracted Universes\")\n",
    "plt.legend()\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-background_subtracted_universes.pdf\".format(save_fig_dir, var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "unif_bin = np.linspace(0., float(len(bins) - 1), len(bins))\n",
    "extent = [unif_bin[0], unif_bin[-1], unif_bin[0], unif_bin[-1]]\n",
    "\n",
    "x_edges = np.array(bins)\n",
    "y_edges = np.array(bins)\n",
    "x_tick_positions = (unif_bin[:-1] + unif_bin[1:]) / 2\n",
    "y_tick_positions = (unif_bin[:-1] + unif_bin[1:]) / 2\n",
    "\n",
    "x_labels = bin_range_labels(x_edges)\n",
    "y_labels = bin_range_labels(y_edges)\n",
    "\n",
    "def plot_heatmap(matrix, title, save_fig=False, save_fig_name=None):\n",
    "    plt.imshow(matrix, extent=extent, origin=\"lower\")\n",
    "    plt.colorbar()\n",
    "    plt.xticks(x_tick_positions, x_labels, rotation=45, ha=\"right\")\n",
    "    plt.yticks(y_tick_positions, y_labels)\n",
    "    plt.xlabel(var_labels[1])\n",
    "    plt.ylabel(var_labels[1])\n",
    "    for i in range(matrix.shape[0]):      # rows (y)\n",
    "        for j in range(matrix.shape[1]):  # columns (x)\n",
    "            value = matrix[i, j]\n",
    "            if not np.isnan(value):  # skip NaNs\n",
    "                plt.text(\n",
    "                    j + 0.5, i + 0.5,\n",
    "                    f\"{value:.2f}\",\n",
    "                    ha=\"center\", va=\"center\",   \n",
    "                    color=get_text_color(value),\n",
    "                    fontsize=10\n",
    "                )\n",
    "    plt.title(title)\n",
    "    if save_fig:\n",
    "        plt.savefig(\"{}.pdf\".format(save_fig_name), bbox_inches='tight')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univ_events = np.array(univ_events)\n",
    "Flux_Covariance = np.cov(univ_events, rowvar=False)\n",
    "Flux_Covariance = np.atleast_2d(Flux_Covariance)\n",
    "print(Flux_Covariance)\n",
    "plot_heatmap(Flux_Covariance, \"Covariance - Flux\")\n",
    "\n",
    "Flux_Covariance_Frac = Flux_Covariance / (nominal_event[:, None] * nominal_event[None, :])\n",
    "plot_heatmap(Flux_Covariance_Frac, \"Fractional Covariance - Flux\")\n",
    "\n",
    "Flux_Correlation = np.corrcoef(univ_events.T)\n",
    "Flux_Correlation = np.atleast_2d(Flux_Correlation)\n",
    "plot_heatmap(Flux_Correlation, \"Correlation - Flux\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nominal_event = fake_data\n",
    "\n",
    "# w/o background\n",
    "nom_Signal = Response @ true_signal\n",
    "\n",
    "GENIE_Covariance_Frac = np.zeros((len(nom_Signal), len(nom_Signal)))\n",
    "GENIE_Covariance = np.zeros((len(nom_Signal), len(nom_Signal)))\n",
    "\n",
    "n_univ_genie = 100\n",
    "for uidx in range(n_univ_genie):\n",
    "    univ_col_evt = (\"GENIE\", \"univ_{}\".format(uidx), \"\", \"\", \"\", \"\", \"\", \"\")\n",
    "    univ_col_mc = (\"GENIE\", \"univ_{}\".format(uidx), \"\")\n",
    "\n",
    "    # new response matrix for univ\n",
    "    reco_vs_true = get_smear_matrix(true_var_signal_sel, var_signal, bins_2d, \n",
    "                                    weights=mc_evt_df[mc_evt_df.nuint_categ == 1][univ_col_evt], plot=False)\n",
    "\n",
    "    true_signal_univ, _ = np.histogram(var_truth_signal, bins=bins, \n",
    "                                    weights=weight_truth_signal*mc_nu_df[mc_nu_df.nuint_categ == 1][univ_col_mc])\n",
    "    eff = get_eff(reco_vs_true, true_signal_univ) # for xsec syst\n",
    "    # eff = get_eff(reco_vs_true, true_signal) # for flux syst\n",
    "    univ_Response = get_response_matrix(reco_vs_true, eff, bins, plot=False)\n",
    "\n",
    "    # signal for univ\n",
    "    univ_Signal = univ_Response @ true_signal #_univ # TODO: check if this is correct\n",
    "\n",
    "    # w/ background for univ # TODO: check if this is correct\n",
    "    # for this_mc_evt_df in mc_evt_df_divided[1:]:\n",
    "    #     weights = this_mc_evt_df[univ_col_evt].copy()\n",
    "    #     weights[np.isnan(weights)] = 1 ## IMPORTANT: make nan weights to 1. to ignore them\n",
    "    #     this_var = this_mc_evt_df[var_evt_reco_col]\n",
    "    #     this_var = np.clip(this_var, bins[0], bins[-1] - eps)\n",
    "    #     background_univ, bins = np.histogram(this_var, bins=bins, weights=weights)\n",
    "    #     univ_Signal += background_univ\n",
    "\n",
    "    plt.hist(bin_centers, bins=bins, weights=univ_Signal, histtype=\"step\", color=\"gray\")\n",
    "\n",
    "\n",
    "    for i in range(len(univ_Signal)):\n",
    "        for j in range(len(univ_Signal)):\n",
    "            # w/o background\n",
    "            nom_i = nom_Signal[i] * xsec_unit\n",
    "            nom_j = nom_Signal[j] * xsec_unit\n",
    "\n",
    "            # w/ background\n",
    "            # nom_i = nominal_event[i] * xsec_unit\n",
    "            # nom_j = nominal_event[j] * xsec_unit\n",
    "\n",
    "            univ_i = univ_Signal[i] * xsec_unit\n",
    "            univ_j = univ_Signal[j] * xsec_unit\n",
    "\n",
    "            frac_cov_entry = ((univ_i - nom_i) / nom_i) * ( (univ_j - nom_j) / nom_j)\n",
    "            if frac_cov_entry > 0:\n",
    "                this_frac_cov = max( frac_cov_entry, eps)\n",
    "            else:\n",
    "                this_frac_cov = min( frac_cov_entry, eps)\n",
    "\n",
    "            cov_entry = (univ_i - nom_i) * (univ_j - nom_j)\n",
    "            if cov_entry > 0:\n",
    "                this_cov = max( cov_entry, eps)\n",
    "            else:\n",
    "                this_cov = min( cov_entry, eps)\n",
    "\n",
    "            GENIE_Covariance[i, j] += this_cov\n",
    "            GENIE_Covariance_Frac[i, j] += this_frac_cov\n",
    "\n",
    "# w/o background\n",
    "plt.hist(bin_centers, bins=bins, weights=nom_Signal, histtype=\"step\", color=\"black\", label=\"nominal_event\")\n",
    "# w/ background\n",
    "# plt.hist(bin_centers, bins=bins, weights=nominal_event, histtype=\"step\", color=\"black\", label=\"nominal_event\")\n",
    "\n",
    "plt.xlim(bins[0], bins[-1])\n",
    "plt.title(\"GENIE\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "GENIE_Covariance_Frac = GENIE_Covariance_Frac / n_univ_genie\n",
    "GENIE_Covariance = GENIE_Covariance / n_univ_genie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(GENIE_Covariance, \"Covariance - GENIE\")\n",
    "plot_heatmap(GENIE_Covariance_Frac, \"Fractional Covariance - GENIE\")\n",
    "\n",
    "GENIE_Correlation = np.zeros_like(GENIE_Covariance)\n",
    "for i in range(len(nominal_event)):\n",
    "    for j in range(len(nominal_event)):\n",
    "        GENIE_Correlation[i, j] = GENIE_Covariance[i, j] / (np.sqrt(GENIE_Covariance[i, i]) * np.sqrt(GENIE_Covariance[j, j]))\n",
    "plot_heatmap(GENIE_Correlation, \"Correlation - GENIE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Covariance_Frac = Flux_Covariance_Frac + GENIE_Covariance_Frac\n",
    "\n",
    "Covariance = np.zeros_like(Covariance_Frac)\n",
    "for i in range(len(nominal_event)):\n",
    "    for j in range(len(nominal_event)):\n",
    "        Covariance[i, j] = Covariance_Frac[i, j] * (nom_Signal[i] * nom_Signal[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(Covariance_Frac, \"Total Fractional Covariance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Singal distribution with error bars from diagonal components of covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# Compute bin centers for error bars\n",
    "\n",
    "frac_uncert = np.sqrt(np.diag(Covariance_Frac))\n",
    "plt.errorbar(bin_centers, nominal_event, yerr=frac_uncert*nominal_event, fmt='o', color='black', label='Subtracted (syst. error)', capsize=3)\n",
    "plt.xlim(bins[0], bins[-1])\n",
    "plt.xlabel(var_labels[0])\n",
    "plt.ylabel(\"Events\")\n",
    "plt.legend()\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-bkg_subtracted_event_rates.pdf\".format(save_fig_dir, var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_type = 2\n",
    "Norm_type = 1\n",
    "unfold = WienerSVD(Response, true_signal, nominal_event, Covariance, C_type, Norm_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfold['unfold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfold['UnfoldCov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unfold = unfold['unfold']\n",
    "UnfoldCov = unfold['UnfoldCov']\n",
    "Unfold_uncert = np.sqrt(np.diag(Covariance))\n",
    "\n",
    "step_handle, = plt.step(bin_edges, np.append(Unfold, Unfold[-1]), where='post', label='Unfolded')\n",
    "bar_handle = plt.bar(\n",
    "    bin_centers,\n",
    "    2*Unfold_uncert,\n",
    "    width=(bin_edges[1] - bin_edges[0]) * 1.,\n",
    "    bottom=Unfold - Unfold_uncert,\n",
    "    color='gray',\n",
    "    alpha=0.5,\n",
    "    linewidth=0,\n",
    "    label='Unfolded Stat. error (box)'\n",
    ")\n",
    "reco_handle, = plt.plot(bin_centers, reco_signal_sel, 'o', label='reco_signal')\n",
    "true_handle, = plt.plot(bin_centers, true_signal, 'o', label='true_signal')\n",
    "\n",
    "# Custom order for legend\n",
    "handles = [step_handle, bar_handle, reco_handle, true_handle]\n",
    "labels = [\n",
    "    'Unfolded',\n",
    "    'Unfolded error',\n",
    "    'reco_signal',\n",
    "    'true_signal'\n",
    "]\n",
    "\n",
    "plt.legend(handles, labels)\n",
    "plt.xlim(bins[0], bins[-1])\n",
    "plt.xlabel(var_labels[0])\n",
    "# plt.ylim(0., 5000.)\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-unfolded_event_rates.pdf\".format(save_fig_dir, var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
