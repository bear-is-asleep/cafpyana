{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wiener SBND Closure Test for 1mu1p Measurement Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib as mpl\n",
    "from os import path\n",
    "import sys\n",
    "import uproot\n",
    "\n",
    "sys.path.append('/exp/sbnd/app/users/munjung/xsec/wienersvd/cafpyana/analysis_village/unfolding')\n",
    "from wienersvd import *\n",
    "from unfolding_inputs import *\n",
    "\n",
    "# import dunestyle.matplotlib as dunestyle\n",
    "plt.style.use(\"presentation.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig = True\n",
    "save_fig_dir = \"./plots/wiener_svd/1mu1p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = mpl.cm.viridis\n",
    "norm = mpl.colors.Normalize(vmin=0.0, vmax=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_split(file):\n",
    "    this_split_df = pd.read_hdf(file, key=\"split\")\n",
    "    this_n_split = this_split_df.n_split.iloc[0]\n",
    "    return this_n_split\n",
    "\n",
    "def print_keys(file):\n",
    "    with pd.HDFStore(file, mode='r') as store:\n",
    "        keys = store.keys()       # list of all keys in the file\n",
    "        print(\"Keys:\", keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dfs(file, keys2load):\n",
    "    out_df_dict = {}\n",
    "    this_n_keys = get_n_split(file)\n",
    "    n_concat = min(n_max_concat, this_n_keys)\n",
    "    for key in keys2load:\n",
    "        dfs = []  # collect all splits for this key\n",
    "        for i in range(n_concat):\n",
    "            this_df = pd.read_hdf(file, key=f\"{key}_{i}\")\n",
    "            dfs.append(this_df)\n",
    "        out_df_dict[key] = pd.concat(dfs, ignore_index=False)\n",
    "\n",
    "    return out_df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- MC study\n",
    "mc_file = \"/exp/sbnd/data/users/munjung/xsec/2025B/MCP_gump_new.df\"\n",
    "mc_split_df = pd.read_hdf(mc_file, key=\"split\")\n",
    "mc_n_split = get_n_split(mc_file)\n",
    "print(\"mc_n_split: %d\" %(mc_n_split))\n",
    "print_keys(mc_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max_concat = 2\n",
    "\n",
    "mc_keys2load = ['evt', 'hdr', 'mcnuwgtslim']\n",
    "mc_dfs = load_dfs(mc_file, mc_keys2load)\n",
    "\n",
    "mc_evt_df = mc_dfs['evt']\n",
    "mc_hdr_df = mc_dfs['hdr']\n",
    "mc_nu_df = mc_dfs['mcnuwgtslim']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move to makedf.py\n",
    "# genie multisims\n",
    "genie_knobs = ['GENIEReWeight_SBN_v1_multisim_ZExpAVariationResponse',\n",
    "               'GENIEReWeight_SBN_v1_multisim_CCRESVariationResponse',\n",
    "               'GENIEReWeight_SBN_v1_multisim_NCRESVariationResponse',\n",
    "               'GENIEReWeight_SBN_v1_multisim_DISBYVariationResponse',\n",
    "               'GENIEReWeight_SBN_v1_multisim_FSI_pi_VariationResponse',\n",
    "               'GENIEReWeight_SBN_v1_multisim_FSI_N_VariationResponse',\n",
    "               'GENIEReWeight_SBN_v1_multisim_NCELVariationResponse']\n",
    "\n",
    "for uidx in range(100):\n",
    "    for kidx, knob in enumerate(genie_knobs):\n",
    "        if kidx == 0:\n",
    "            mc_evt_df[(\"GENIE\", \"univ_{}\".format(uidx), \"\", \"\", \"\", \"\", \"\", \"\")] = mc_evt_df[(knob, \"univ_{}\".format(uidx), \"\", \"\", \"\", \"\", \"\", \"\")]\n",
    "            mc_nu_df[(\"GENIE\", \"univ_{}\".format(uidx), \"\")] = mc_nu_df[(knob, \"univ_{}\".format(uidx), \"\")]\n",
    "        else:\n",
    "            mc_evt_df[(\"GENIE\", \"univ_{}\".format(uidx), \"\", \"\", \"\", \"\", \"\", \"\")] *= mc_evt_df[(knob, \"univ_{}\".format(uidx), \"\", \"\", \"\", \"\", \"\", \"\")]\n",
    "            mc_nu_df[(\"GENIE\", \"univ_{}\".format(uidx), \"\")] *= mc_nu_df[(knob, \"univ_{}\".format(uidx), \"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## total pot\n",
    "mc_tot_pot = mc_hdr_df['pot'].sum()\n",
    "print(\"mc_tot_pot: %.3e\" %(mc_tot_pot))\n",
    "\n",
    "target_pot = 1e20\n",
    "mc_pot_scale = target_pot / mc_tot_pot\n",
    "print(\"mc_pot_scale: %.3e\" %(mc_pot_scale))\n",
    "mc_pot_scale = 1.\n",
    "\n",
    "mc_evt_df[\"pot_weight\"] = mc_pot_scale * np.ones(len(mc_evt_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: z-dependence?\n",
    "# flux file, units: /m^2/10^6 POT \n",
    "# 50 MeV bins\n",
    "fluxfile = \"/exp/sbnd/data/users/munjung/flux/sbnd_original_flux.root\"\n",
    "flux = uproot.open(fluxfile)\n",
    "print(flux.keys())\n",
    "\n",
    "# numu flux\n",
    "numu_flux = flux[\"flux_sbnd_numu\"].to_numpy()\n",
    "bin_edges = numu_flux[1]\n",
    "flux_vals = numu_flux[0]\n",
    "\n",
    "plt.hist(bin_edges[:-1], bins=bin_edges, weights=flux_vals, histtype=\"step\")\n",
    "plt.xlabel(\"E [GeV]\")\n",
    "plt.ylabel(\"Flux [/m$^{2}$/10$^{6}$ POT]\")\n",
    "plt.title(\"SBND $\\\\nu_\\\\mu$ Flux\")\n",
    "plt.show()\n",
    "\n",
    "# get integrated flux\n",
    "integrated_flux = flux_vals.sum()\n",
    "integrated_flux /= 1e4 # to cm2\n",
    "INTEGRATED_FLUX = integrated_flux * mc_tot_pot / 1e6 # POT\n",
    "print(\"Integrated flux: %.3e\" % INTEGRATED_FLUX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RHO = 1.3836  #g/cm3, liquid Ar density\n",
    "N_A = 6.02214076e23 # Avogadroâ€™s number\n",
    "M_AR = 39.95 # g, molar mass of argon\n",
    "V_SBND = 380 * 380 * 440 # cm3, the active volume of the detector \n",
    "NTARGETS = RHO * V_SBND * N_A / M_AR\n",
    "print(\"# of targets: \", NTARGETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to 1 for event rates\n",
    "XSEC_UNIT = 1 / (INTEGRATED_FLUX * NTARGETS)\n",
    "\n",
    "# XSEC_UNIT = 1\n",
    "print(\"xsec unit: \", XSEC_UNIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate MC stat universes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_seeds = []\n",
    "for i in range(len(mc_evt_df)):\n",
    "    # Create a unique seed based on event index\n",
    "    # Using a hash function that's deterministic\n",
    "    unique_seed = hash(f\"event_{i}\") % (2**32)  # Ensure it's a 32-bit integer\n",
    "    event_seeds.append(unique_seed)\n",
    "# make sure the seeds are unique!\n",
    "assert len(event_seeds) == len(set(event_seeds))\n",
    "\n",
    "# generate universes\n",
    "n_universes = 100\n",
    "MCstat_univ_events = np.zeros((n_universes, len(mc_evt_df)))\n",
    "poisson_mean = 1.0\n",
    "\n",
    "# get Poisson weights and save to \"MCstat.univ_\"\n",
    "# dummy df to hold the weights -- iterative inserting causes PerformanceWarning\n",
    "mcstat_univ_cols = pd.MultiIndex.from_product(\n",
    "    [[\"MCstat\"], [f\"univ_{i}\" for i in range(n_universes)], [\"\"], [\"\"], [\"\"], [\"\"], [\"\"], [\"\"]],\n",
    ")\n",
    "mcstat_univ_wgt = pd.DataFrame(\n",
    "    1.0,\n",
    "    index=mc_evt_df.index,\n",
    "    columns=mcstat_univ_cols,\n",
    ")\n",
    "\n",
    "for uidx in range(n_universes):\n",
    "    universe_seed = hash(f\"universe_{uidx}\") % (2**32)\n",
    "    \n",
    "    poisson_weights = []\n",
    "    for event_idx, event_seed in enumerate(event_seeds):\n",
    "        # Combine universe seed with event seed for unique randomness per event per universe\n",
    "        combined_seed = (universe_seed + event_seed) % (2**32)\n",
    "        np.random.seed(combined_seed)\n",
    "        \n",
    "        poisson_val = np.random.poisson(poisson_mean)\n",
    "        poisson_weights.append(poisson_val)\n",
    "    \n",
    "    # insert universe weights into df\n",
    "    mcstat_univ_wgt[(\"MCstat\", \"univ_{}\".format(uidx), \"\", \"\", \"\", \"\", \"\", \"\")] = np.array(poisson_weights)\n",
    "    MCstat_univ_events[uidx, :] = np.array(poisson_weights)\n",
    "\n",
    "mc_evt_df = mc_evt_df.join(mcstat_univ_wgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InFV(data): # cm\n",
    "    xmin = -190.\n",
    "    ymin = -190.\n",
    "    zmin = 10.\n",
    "    xmax = 190.\n",
    "    ymax =  190.\n",
    "    zmax =  450.\n",
    "    return (np.abs(data.x) > 10) & (np.abs(data.x) < 190) & (data.y > ymin) & (data.y < ymax) & (data.z > zmin) & (data.z < zmax)\n",
    "\n",
    "\n",
    "def IsNu(df):\n",
    "    return ~df.pdg.isna()\n",
    "\n",
    "\n",
    "def IsSignal(df): # definition                                                                                                                                                                                                                                                                         \n",
    "    is_fv = InFV(df.position)\n",
    "    is_1mu1p0pi = (df.nmu_27MeV == 1) & (df.npi_30MeV == 0) & (df.np_50MeV == 1) & (df.npi0 == 0) & (df.mu.genE > 0.25) # & (df.np_20MeV == 1) : add with stubs\n",
    "    return is_fv & is_1mu1p0pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_int_category(df):\n",
    "    is_notnu = ~IsNu(df)\n",
    "    is_nu_outfv = IsNu(df) & ~InFV(df.position)\n",
    "    is_signal = IsSignal(df)\n",
    "    is_other_nu_infv = IsNu(df) & InFV(df.position) & ~IsSignal(df)\n",
    "\n",
    "    nuint_categ = pd.Series(8, index=df.index)\n",
    "    nuint_categ[is_notnu] = -1  # not nu\n",
    "    nuint_categ[is_nu_outfv] = 0  # nu out of FV\n",
    "    nuint_categ[is_signal] = 1    # nu in FV, signal\n",
    "    nuint_categ[is_other_nu_infv] = 2  # nu in FV, not signal\n",
    "\n",
    "    return nuint_categ\n",
    "\n",
    "\n",
    "# signal need to come first for below code to work\n",
    "mode_list = [1, 2, 0, -1]\n",
    "mode_labels = [\"Signal\", \"Non-sig. FV Nu\", \"Non FV Nu\", \"Not Nu\"]\n",
    "colors = ['#d62728',  # Red            \n",
    "          '#1f77b4',  # Blue\n",
    "          '#ff7f0e',\n",
    "          '#7f7f7f']  # Gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ccqe selection\n",
    "\n",
    "# in FV\n",
    "# print(InFV(mc_evt_df.slc.vertex).value_counts())\n",
    "mc_evt_df = mc_evt_df[InFV(mc_evt_df.slc.vertex)]\n",
    "\n",
    "# mc_evt_df = mc_evt_df[(mc_evt_df.slc.nu_score > 0.5)]\n",
    "\n",
    "# # mu length cut\n",
    "# mc_evt_df = mc_evt_df[mc_evt_df.mu.pfp.trk.len > 50]\n",
    "\n",
    "# # mu containment cut\n",
    "# mc_evt_df = mc_evt_df[mc_evt_df.mu.pfp.trk.is_contained == True]\n",
    "\n",
    "# # mu chi2 cut \n",
    "# mc_evt_df = mc_evt_df[(mc_evt_df.mu.pfp.trk.chi2pid.I2.chi2_muon > 0) & (mc_evt_df.mu.pfp.trk.chi2pid.I2.chi2_muon < 25) & (mc_evt_df.mu.pfp.trk.chi2pid.I2.chi2_proton > 100)]\n",
    "\n",
    "# # protons chi2 cut \n",
    "# mc_evt_df = mc_evt_df[(mc_evt_df.p.pfp.trk.chi2pid.I2.chi2_muon > 0) & (mc_evt_df.p.pfp.trk.chi2pid.I2.chi2_muon < 90)]\n",
    "\n",
    "# 1p0pi\n",
    "twoprong_cut = (np.isnan(mc_evt_df.other_shw_length) & np.isnan(mc_evt_df.other_trk_length))\n",
    "mc_evt_df = mc_evt_df[twoprong_cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move this to makedf.py\n",
    "mc_evt_df.loc[:, (\"mu\",\"pfp\",\"trk\",\"truth\",\"p\",\"totp\",\"\",\"\")] = np.sqrt(mc_evt_df.mu.pfp.trk.truth.p.genp.x**2 + mc_evt_df.mu.pfp.trk.truth.p.genp.y**2 + mc_evt_df.mu.pfp.trk.truth.p.genp.z**2)\n",
    "mc_nu_df.loc[:, ('mu','totp','')] = np.sqrt(mc_nu_df.mu.genp.x**2 + mc_nu_df.mu.genp.y**2 + mc_nu_df.mu.genp.z**2)\n",
    "\n",
    "mc_evt_df.loc[:, (\"mu\",\"pfp\",\"trk\",\"truth\",\"p\",\"dir\",\"x\",\"\")] = mc_evt_df.mu.pfp.trk.truth.p.genp.x/mc_evt_df.mu.pfp.trk.truth.p.totp\n",
    "mc_evt_df.loc[:, (\"mu\",\"pfp\",\"trk\",\"truth\",\"p\",\"dir\",\"y\",\"\")] = mc_evt_df.mu.pfp.trk.truth.p.genp.y/mc_evt_df.mu.pfp.trk.truth.p.totp\n",
    "mc_evt_df.loc[:, (\"mu\",\"pfp\",\"trk\",\"truth\",\"p\",\"dir\",\"z\",\"\")] = mc_evt_df.mu.pfp.trk.truth.p.genp.z/mc_evt_df.mu.pfp.trk.truth.p.totp\n",
    "\n",
    "mc_nu_df.loc[:, (\"mu\",\"dir\",\"x\")] = mc_nu_df.mu.genp.x/mc_nu_df.mu.totp\n",
    "mc_nu_df.loc[:, (\"mu\",\"dir\",\"y\")] = mc_nu_df.mu.genp.y/mc_nu_df.mu.totp\n",
    "mc_nu_df.loc[:, (\"mu\",\"dir\",\"z\")] = mc_nu_df.mu.genp.z/mc_nu_df.mu.totp\n",
    "\n",
    "mc_evt_df.loc[:, (\"p\",\"pfp\",\"trk\",\"truth\",\"p\",\"totp\",\"\",\"\")] = np.sqrt(mc_evt_df.p.pfp.trk.truth.p.genp.x**2 + mc_evt_df.p.pfp.trk.truth.p.genp.y**2 + mc_evt_df.p.pfp.trk.truth.p.genp.z**2)\n",
    "mc_nu_df.loc[:, ('p','totp','')] = np.sqrt(mc_nu_df.p.genp.x**2 + mc_nu_df.p.genp.y**2 + mc_nu_df.p.genp.z**2)\n",
    "\n",
    "mc_evt_df.loc[:, (\"p\",\"pfp\",\"trk\",\"truth\",\"p\",\"dir\",\"x\",\"\")] = mc_evt_df.p.pfp.trk.truth.p.genp.x/mc_evt_df.p.pfp.trk.truth.p.totp\n",
    "mc_evt_df.loc[:, (\"p\",\"pfp\",\"trk\",\"truth\",\"p\",\"dir\",\"y\",\"\")] = mc_evt_df.p.pfp.trk.truth.p.genp.y/mc_evt_df.p.pfp.trk.truth.p.totp\n",
    "mc_evt_df.loc[:, (\"p\",\"pfp\",\"trk\",\"truth\",\"p\",\"dir\",\"z\",\"\")] = mc_evt_df.p.pfp.trk.truth.p.genp.z/mc_evt_df.p.pfp.trk.truth.p.totp\n",
    "\n",
    "mc_nu_df.loc[:, (\"p\",\"dir\",\"x\")] = mc_nu_df.p.genp.x/mc_nu_df.p.totp\n",
    "mc_nu_df.loc[:, (\"p\",\"dir\",\"y\")] = mc_nu_df.p.genp.y/mc_nu_df.p.totp\n",
    "mc_nu_df.loc[:, (\"p\",\"dir\",\"z\")] = mc_nu_df.p.genp.z/mc_nu_df.p.totp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify events into categories\n",
    "mc_evt_df.loc[:,'nuint_categ'] = get_int_category(mc_evt_df)\n",
    "mc_nu_df.loc[:,'nuint_categ'] = get_int_category(mc_nu_df)\n",
    "\n",
    "print(mc_evt_df.nuint_categ.value_counts())\n",
    "print(mc_nu_df.nuint_categ.value_counts()) # won't have -1 because nudf is all nu events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# muon momentum\n",
    "var_save_name = \"muon-p\"\n",
    "\n",
    "var_labels = [r\"$\\mathrm{P_\\mu~[GeV/c]}$\", \n",
    "              r\"$\\mathrm{P_\\mu^{reco.}~[GeV/c]}$\",  # reco\n",
    "              r\"$\\mathrm{P_\\mu^{true}~[GeV/c]}$\"]  # true\n",
    "\n",
    "bins = np.linspace(0.2, 2, 6)\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2.\n",
    "\n",
    "var_evt_reco_col = ('mu', 'pfp', 'trk', 'P', 'p_muon', '', '', '')\n",
    "var_evt_truth_col = ('mu', 'pfp', 'trk', 'truth', 'p', 'totp', '', '')\n",
    "var_nu_col = ('mu', 'totp', '')\n",
    "\n",
    "# # muon dir z\n",
    "# var_save_name = \"muon-dir_z\"\n",
    "\n",
    "# var_labels = [r\"$\\mathrm{cos(\\theta_\\mu)}$\",\n",
    "#               r\"$\\mathrm{cos(\\theta_\\mu^{reco.})}$\",\n",
    "#               r\"$\\mathrm{cos(\\theta_\\mu^{true})}$\"]\n",
    "\n",
    "# bins = np.linspace(-1, 1, 6)\n",
    "# bin_centers = (bins[:-1] + bins[1:]) / 2.\n",
    "\n",
    "# var_evt_reco_col = ('mu', 'pfp', 'trk', 'dir', 'z', '', '', '')\n",
    "# var_evt_truth_col = ('mu', 'pfp', 'trk', 'truth', 'p', 'dir', 'z', '')\n",
    "# var_nu_col = ('mu', 'dir', 'z')\n",
    "\n",
    "# proton momentum\n",
    "# var_save_name = \"proton-p\"\n",
    "\n",
    "# var_labels = [r\"$\\mathrm{P_p~[GeV/c]}$\", \n",
    "#               r\"$\\mathrm{P_p^{reco.}~[GeV/c]}$\",  # reco\n",
    "#               r\"$\\mathrm{P_p^{true}~[GeV/c]}$\"]  # true\n",
    "\n",
    "# bins = np.linspace(0.2, 2, 6)\n",
    "# bin_centers = (bins[:-1] + bins[1:]) / 2.\n",
    "\n",
    "# var_evt_reco_col = ('p', 'pfp', 'trk', 'P', 'p_proton', '', '', '')\n",
    "# var_evt_truth_col = ('p', 'pfp', 'trk', 'truth', 'p', 'totp', '', '')\n",
    "# var_nu_col = ('p', 'totp', '')\n",
    "\n",
    "# # proton dir z\n",
    "# var_save_name = \"proton-dir_z\"\n",
    "\n",
    "# var_labels = [r\"$\\mathrm{cos(\\theta_p)}$\",\n",
    "#               r\"$\\mathrm{cos(\\theta_p^{reco.})}$\",\n",
    "#               r\"$\\mathrm{cos(\\theta_p^{true})}$\"]\n",
    "\n",
    "# bins = np.linspace(-1, 1, 6)\n",
    "# bin_centers = (bins[:-1] + bins[1:]) / 2.\n",
    "\n",
    "# var_evt_reco_col = ('p', 'pfp', 'trk', 'dir', 'z', '', '', '')\n",
    "# var_evt_truth_col = ('p', 'pfp', 'trk', 'truth', 'p', 'dir', 'z', '')\n",
    "# var_nu_col = ('p', 'dir', 'z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.clip is for including underflow events into the first bin and overflow events into the last bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total MC reco muon momentum: for fake data\n",
    "eps = 1e-8\n",
    "var_total_mc = mc_evt_df[var_evt_reco_col]\n",
    "var_total_mc = np.clip(var_total_mc, bins[0], bins[-1] - eps)\n",
    "\n",
    "# mc_evt_df divided into mode for subtraction from data in futre\n",
    "# first item in list is the signal\n",
    "mc_evt_df_divided = [mc_evt_df[mc_evt_df.nuint_categ == mode]for mode in mode_list]\n",
    "\n",
    "# Reco muon momentum for each 'nuint_categ' for stack plot and subtraction from the fake data\n",
    "var_per_nuint_categ_mc = [mc_evt_df[mc_evt_df.nuint_categ == mode][var_evt_reco_col]for mode in mode_list]\n",
    "var_per_nuint_categ_mc = [s.clip(bins[0], bins[-1] - eps) for s in var_per_nuint_categ_mc]\n",
    "weights_per_categ = [mc_evt_df.loc[mc_evt_df.nuint_categ == mode, 'pot_weight'] for mode in mode_list]\n",
    "\n",
    "# for response matrix\n",
    "# Signal event's reco muon momentum after the event selection\n",
    "var_signal = mc_evt_df[mc_evt_df.nuint_categ == 1][var_evt_reco_col]\n",
    "var_signal = np.clip(var_signal, bins[0], bins[-1] - eps)\n",
    "weight_signal = mc_evt_df.loc[mc_evt_df.nuint_categ == 1, 'pot_weight']\n",
    "\n",
    "# Signal event's true muon momentum after the event selection\n",
    "true_var_signal_sel = mc_evt_df[mc_evt_df.nuint_categ == 1][var_evt_truth_col]\n",
    "true_var_signal_sel = np.clip(true_var_signal_sel, bins[0], bins[-1] - eps)\n",
    "weight_true_signal = mc_evt_df.loc[mc_evt_df.nuint_categ == 1, 'pot_weight']\n",
    "\n",
    "# for efficiency vector\n",
    "# Signal event's true muon momentum without event selection\n",
    "var_truth_signal = mc_nu_df[mc_nu_df.nuint_categ == 1][var_nu_col]\n",
    "var_truth_signal = np.clip(var_truth_signal, bins[0], bins[-1] - eps)\n",
    "weight_truth_signal = np.full_like(var_truth_signal, mc_pot_scale, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw true (before event selection) and reco (after event selection) muon momentum distributions of signal events.\n",
    "Print entries for double check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_signal, _, _ = plt.hist(var_truth_signal, bins=bins, weights=weight_truth_signal, histtype=\"step\", label=\"True Signal\")\n",
    "reco_signal_sel, _, _ = plt.hist(var_signal, bins=bins, weights=weight_signal, histtype=\"step\", label=\"Reco Selected Signal\", color=\"k\")\n",
    "true_signal_sel, _, _ = plt.hist(true_var_signal_sel, bins=bins, weights=weight_signal, histtype=\"step\", label=\"True Selected Signal\")\n",
    "print(true_signal)\n",
    "print(reco_signal_sel)\n",
    "print(true_signal_sel)\n",
    "plt.legend()\n",
    "plt.ylabel(\"Events\")\n",
    "plt.xlim(bins[0], bins[-1])\n",
    "plt.xlabel(var_labels[0])\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-sel_event_rates.pdf\".format(save_fig_dir, var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_2d = bins# = [np.array([0.2, 2]), np.array([0.2, 2])] # commented out lines for 1 bin MC closure test\n",
    "\n",
    "save_fig_name = \"{}/{}-reco_vs_true\".format(save_fig_dir, var_save_name)\n",
    "reco_vs_true = get_smear_matrix(true_var_signal_sel, var_signal, bins_2d, var_labels=var_labels,\n",
    "                                save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "eff = get_eff(reco_vs_true, true_signal)\n",
    "print(\"eff\")\n",
    "print(eff)\n",
    "\n",
    "save_fig_name = \"{}/{}-response_matrix\".format(save_fig_dir, var_save_name)\n",
    "Response = get_response_matrix(reco_vs_true, eff, bins, var_labels=var_labels,\n",
    "                               save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretty heatmap plotter\n",
    "\n",
    "unif_bin = np.linspace(0., float(len(bins) - 1), len(bins))\n",
    "extent = [unif_bin[0], unif_bin[-1], unif_bin[0], unif_bin[-1]]\n",
    "\n",
    "x_edges = np.array(bins)\n",
    "y_edges = np.array(bins)\n",
    "x_tick_positions = (unif_bin[:-1] + unif_bin[1:]) / 2\n",
    "y_tick_positions = (unif_bin[:-1] + unif_bin[1:]) / 2\n",
    "\n",
    "x_labels = bin_range_labels(x_edges)\n",
    "y_labels = bin_range_labels(y_edges)\n",
    "\n",
    "def plot_heatmap(matrix, title, plot_labels=var_labels, save_fig=False, save_fig_name=None):\n",
    "    plt.imshow(matrix, extent=extent, origin=\"lower\")\n",
    "    plt.colorbar()\n",
    "    plt.xticks(x_tick_positions, x_labels, rotation=45, ha=\"right\")\n",
    "    plt.yticks(y_tick_positions, y_labels)\n",
    "    plt.xlabel(plot_labels[0])\n",
    "    plt.ylabel(plot_labels[1])\n",
    "    for i in range(matrix.shape[0]):      # rows (y)\n",
    "        for j in range(matrix.shape[1]):  # columns (x)\n",
    "            value = matrix[i, j]\n",
    "            if not np.isnan(value):  # skip NaNs\n",
    "                plt.text(\n",
    "                    j + 0.5, i + 0.5,\n",
    "                    f\"{value:.2f}\",\n",
    "                    ha=\"center\", va=\"center\",   \n",
    "                    color=get_text_color(value),\n",
    "                    fontsize=10\n",
    "                )\n",
    "    plt.title(title)\n",
    "    if save_fig:\n",
    "        plt.savefig(\"{}.pdf\".format(save_fig_name), bbox_inches='tight')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xsec covariance calculater\n",
    "# TODO: convert unit using XSEC_UNIT\n",
    "def get_xsec_covariance(syst_name, n_univ, reco_signal_sel, true_var_signal_sel, var_signal, bins, var_labels,\n",
    "                        save_fig=False, save_fig_name=None):\n",
    "    signal_cv = reco_signal_sel * XSEC_UNIT # = Response @ true_signal\n",
    "\n",
    "    Covariance_Frac = np.zeros((len(signal_cv), len(signal_cv)))\n",
    "    Covariance = np.zeros((len(signal_cv), len(signal_cv)))\n",
    "\n",
    "    univ_events = []\n",
    "    for uidx in range(n_univ):\n",
    "        univ_col_evt = (syst_name, \"univ_{}\".format(uidx), \"\", \"\", \"\", \"\", \"\", \"\")\n",
    "        univ_col_mc = (syst_name, \"univ_{}\".format(uidx), \"\")\n",
    "\n",
    "        # new response matrix for univ\n",
    "        reco_vs_true = get_smear_matrix(true_var_signal_sel, var_signal, bins, \n",
    "                                        weights=mc_evt_df[mc_evt_df.nuint_categ == 1][univ_col_evt], plot=False)\n",
    "\n",
    "        if syst_name == \"GENIE\":\n",
    "            # for xsec syst\n",
    "            true_signal_univ, _ = np.histogram(var_truth_signal, bins=bins, \n",
    "                                            weights=weight_truth_signal*mc_nu_df[mc_nu_df.nuint_categ == 1][univ_col_mc])\n",
    "            \n",
    "            eff = get_eff(reco_vs_true, true_signal_univ) \n",
    "\n",
    "        elif syst_name == \"Flux\" or syst_name == \"MCstat\":\n",
    "            # for flux syst\n",
    "\n",
    "            eff = get_eff(reco_vs_true, true_signal)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid syst_name: {}\".format(syst_name))\n",
    "\n",
    "        Response_univ = get_response_matrix(reco_vs_true, eff, bins, plot=False)\n",
    "        signal_univ = Response_univ @ true_signal * XSEC_UNIT #_univ # TODO:\n",
    "\n",
    "        # loop over background categories\n",
    "        # + univ background - cv background\n",
    "        # note: cv background subtraction cancels out with the cv background subtraction for the cv event rate. \n",
    "        #       doing it anyways for the plot of universes on background subtracted event rate.\n",
    "        for this_mc_evt_df in mc_evt_df_divided[1:]:\n",
    "            weights = this_mc_evt_df[univ_col_evt].copy()\n",
    "            weights[np.isnan(weights)] = 1 ## IMPORTANT: make nan weights to 1. to ignore them\n",
    "            this_var = this_mc_evt_df[var_evt_reco_col]\n",
    "            this_var = np.clip(this_var, bins[0], bins[-1] - eps)\n",
    "            background_univ, bins = np.histogram(this_var, bins=bins, weights=weights)\n",
    "            background_cv, bins = np.histogram(this_var, bins=bins)\n",
    "            background_univ = np.array(background_univ) * XSEC_UNIT\n",
    "            background_cv = np.array(background_cv) * XSEC_UNIT\n",
    "            signal_univ += background_univ - background_cv\n",
    "\n",
    "        univ_events.append(signal_univ)\n",
    "        plt.hist(bin_centers, bins=bins, weights=signal_univ, histtype=\"step\", color=\"gray\")\n",
    "\n",
    "        for i in range(len(signal_univ)):\n",
    "            for j in range(len(signal_univ)):\n",
    "                nom_i = signal_cv[i] \n",
    "                nom_j = signal_cv[j] \n",
    "\n",
    "                univ_i = signal_univ[i] \n",
    "                univ_j = signal_univ[j] \n",
    "\n",
    "                frac_cov_entry = ((univ_i - nom_i) / nom_i) * ( (univ_j - nom_j) / nom_j)\n",
    "                if frac_cov_entry > 0:\n",
    "                    this_frac_cov = max( frac_cov_entry, eps)\n",
    "                else:\n",
    "                    this_frac_cov = min( frac_cov_entry, eps)\n",
    "\n",
    "                cov_entry = (univ_i - nom_i) * (univ_j - nom_j)\n",
    "                if cov_entry > 0:\n",
    "                    this_cov = max( cov_entry, eps)\n",
    "                else:\n",
    "                    this_cov = min( cov_entry, eps)\n",
    "\n",
    "                Covariance[i, j] += this_cov\n",
    "                Covariance_Frac[i, j] += this_frac_cov\n",
    "\n",
    "    plt.hist(bin_centers, bins=bins, weights=signal_cv, histtype=\"step\", color=\"black\", label=\"nominal_event\")\n",
    "\n",
    "    plt.xlim(bins[0], bins[-1])\n",
    "    plt.xlabel(var_labels[0])\n",
    "    plt.ylabel(\"Events\")\n",
    "    plt.title(syst_name)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    Covariance_Frac = Covariance_Frac / n_univ\n",
    "    Covariance = Covariance / n_univ\n",
    "\n",
    "    Correlation = np.zeros_like(Covariance)\n",
    "    for i in range(len(signal_cv)):\n",
    "        for j in range(len(signal_cv)):\n",
    "            Correlation[i, j] = Covariance[i, j] / (np.sqrt(Covariance[i, i]) * np.sqrt(Covariance[j, j]))\n",
    "\n",
    "    if save_fig:\n",
    "        plt.savefig(\"{}.pdf\".format(save_fig_name), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    return {\"Covariance_Frac\": Covariance_Frac, \n",
    "            \"Covariance\": Covariance,\n",
    "            \"Correlation\": Correlation,\n",
    "            \"cv_events\": signal_cv,\n",
    "            \"univ_events\": univ_events,\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC Stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the average of universes' weights is ~ CV value\n",
    "univ_avg = mc_evt_df.MCstat.mean(axis=1)\n",
    "fig, ax = plt.subplots(2,1, figsize=(6, 6), sharex=True, gridspec_kw={'height_ratios': [2, 1]})\n",
    "cv_events, _, _ = ax[0].hist(mc_evt_df[var_evt_reco_col], bins=bins, histtype=\"step\", color=\"black\", label=\"nominal_event\")\n",
    "univ_avg_events, _, _ = ax[0].hist(mc_evt_df[var_evt_reco_col], bins=bins, weights=univ_avg, histtype=\"step\", color=\"red\", label=\"univ_avg\")\n",
    "ax[0].set_xlim(bins[0], bins[-1])\n",
    "ax[0].set_ylabel(\"Events\")\n",
    "ax[0].legend()\n",
    "\n",
    "bin_centers = (bins[1:] + bins[:-1]) / 2\n",
    "ratio = univ_avg_events/cv_events\n",
    "ax[1].hist(bin_centers, bins=bins, weights=ratio, histtype=\"step\", color=\"black\")\n",
    "ax[1].set_xlim(bins[0], bins[-1])\n",
    "ax[1].set_xlabel(var_labels[0])\n",
    "ax[1].set_ylabel(\"univ_avg/CV\")\n",
    "ax[1].set_xlabel(var_labels[0])\n",
    "ax[1].set_ylim(0.9, 1.1)\n",
    "\n",
    "tolerance = 0.05\n",
    "if np.all(np.abs(ratio - 1) < tolerance):\n",
    "    print(\"The average of universes' weights is within the tolerance of the CV value\")\n",
    "else:\n",
    "    print(\"The average of universes' weights is not within the tolerance of the CV value\")\n",
    "\n",
    "for uidx in range(n_universes):\n",
    "    # print(uidx)\n",
    "    plt.hist(mc_evt_df[var_evt_reco_col], bins=bins, weights=mc_evt_df[\"MCstat\"][f\"univ_{uidx}\"], histtype=\"step\", color=\"gray\")\n",
    "\n",
    "plt.hist(mc_evt_df[var_evt_reco_col], bins=bins, histtype=\"step\", color=\"black\", label=\"nominal_event\")\n",
    "plt.xlim(bins[0], bins[-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syst_name = \"MCstat\"\n",
    "n_univ = 100\n",
    "\n",
    "save_fig_name = \"{}/{}-{}-mcstat_univ_events\".format(save_fig_dir, var_save_name, syst_name)\n",
    "ret_mcstat = get_xsec_covariance(syst_name, n_univ, reco_signal_sel, true_var_signal_sel, var_signal, bins, var_labels,\n",
    "                               save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_name = \"{}/{}-{}-mcstat_covariance\".format(save_fig_dir, var_save_name, syst_name)\n",
    "plot_heatmap(ret_mcstat[\"Covariance\"], \"Covariance - mcstat\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "save_fig_name = \"{}/{}-{}-mcstat_covariance_frac\".format(save_fig_dir, var_save_name, syst_name)\n",
    "plot_heatmap(ret_mcstat[\"Covariance_Frac\"], \"Fractional Covariance - mcstat\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "save_fig_name = \"{}/{}-{}-mcstat_correlation\".format(save_fig_dir, var_save_name, syst_name)\n",
    "plot_heatmap(ret_mcstat[\"Correlation\"], \"Correlation - mcstat\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syst_name = \"Flux\"\n",
    "n_univ = 1000\n",
    "\n",
    "save_fig_name = \"{}/{}-{}-flux_univ_events\".format(save_fig_dir, var_save_name, syst_name)\n",
    "ret_flux = get_xsec_covariance(syst_name, n_univ, reco_signal_sel, true_var_signal_sel, var_signal, bins, var_labels,\n",
    "                               save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_name = \"{}/{}-{}-flux_covariance\".format(save_fig_dir, var_save_name, syst_name)\n",
    "plot_heatmap(ret_flux[\"Covariance\"], \"Covariance - Flux\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "save_fig_name = \"{}/{}-{}-flux_covariance_frac\".format(save_fig_dir, var_save_name, syst_name)\n",
    "plot_heatmap(ret_flux[\"Covariance_Frac\"], \"Fractional Covariance - Flux\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "save_fig_name = \"{}/{}-{}-flux_correlation\".format(save_fig_dir, var_save_name, syst_name)\n",
    "plot_heatmap(ret_flux[\"Correlation\"], \"Correlation - Flux\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syst_name = \"GENIE\"\n",
    "n_univ = 100\n",
    "\n",
    "save_fig_name = \"{}/{}-{}-genie_univ_events\".format(save_fig_dir, var_save_name, syst_name)\n",
    "ret_genie = get_xsec_covariance(syst_name, n_univ, reco_signal_sel, true_var_signal_sel, var_signal, bins, var_labels,\n",
    "                                save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_name = \"{}/{}-{}-genie_covariance\".format(save_fig_dir, var_save_name, syst_name)\n",
    "plot_heatmap(ret_genie[\"Covariance\"], \"Covariance - GENIE\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "save_fig_name = \"{}/{}-{}-genie_covariance_frac\".format(save_fig_dir, var_save_name, syst_name)\n",
    "plot_heatmap(ret_genie[\"Covariance_Frac\"], \"Fractional Covariance - GENIE\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)\n",
    "save_fig_name = \"{}/{}-{}-genie_correlation\".format(save_fig_dir, var_save_name, syst_name)\n",
    "plot_heatmap(ret_genie[\"Correlation\"], \"Correlation - Flux\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "Covariance_Frac = ret_flux[\"Covariance_Frac\"] + ret_genie[\"Covariance_Frac\"] + ret_mcstat[\"Covariance_Frac\"]\n",
    "\n",
    "Covariance = np.zeros_like(Covariance_Frac)\n",
    "for i in range(len(bins)-1):\n",
    "    for j in range(len(bins)-1):\n",
    "        Covariance[i, j] = Covariance_Frac[i, j] * (reco_signal_sel[i] * reco_signal_sel[j]) * XSEC_UNIT**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_name = \"{}/{}-{}-total_covariance_frac\".format(save_fig_dir, var_save_name, syst_name)\n",
    "plot_heatmap(Covariance_Frac, \"Total Fractional Covariance\",\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fractional uncertainty\n",
    "frac_uncert_flux = np.sqrt(np.diag(ret_flux[\"Covariance_Frac\"]))\n",
    "frac_uncert_genie = np.sqrt(np.diag(ret_genie[\"Covariance_Frac\"]))\n",
    "frac_uncert_mcstat = np.sqrt(np.diag(ret_mcstat[\"Covariance_Frac\"]))\n",
    "frac_uncert_total = np.sqrt(np.diag(Covariance_Frac))\n",
    "\n",
    "plt.hist(bin_centers, bins=bins, weights=frac_uncert_flux*1e2, histtype=\"step\", color=\"C0\", label=\"Flux\")\n",
    "plt.hist(bin_centers, bins=bins, weights=frac_uncert_genie*1e2, histtype=\"step\", color=\"C1\", label=\"GENIE\")\n",
    "plt.hist(bin_centers, bins=bins, weights=frac_uncert_mcstat*1e2, histtype=\"step\", color=\"C2\", label=\"MCstat\")\n",
    "plt.hist(bin_centers, bins=bins, weights=frac_uncert_total*1e2, histtype=\"step\", color=\"k\", label=\"Total\")\n",
    "\n",
    "plt.xlim(bins[0], bins[-1])\n",
    "plt.xlabel(var_labels[0])\n",
    "plt.ylabel(\"Uncertainty [%]\")\n",
    "plt.legend()\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-uncertainty_breakdown.pdf\".format(save_fig_dir, var_save_name), bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Singal distribution with error bars from diagonal components of covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bin centers for error bars\n",
    "frac_uncert = np.sqrt(np.diag(Covariance_Frac))\n",
    "plt.errorbar(bin_centers, reco_signal_sel*XSEC_UNIT, yerr=frac_uncert*reco_signal_sel*XSEC_UNIT, fmt='o', color='black', label='Subtracted (syst. error)', capsize=3)\n",
    "plt.xlim(bins[0], bins[-1])\n",
    "plt.xlabel(var_labels[0])\n",
    "plt.ylabel(\"Events\")\n",
    "plt.legend()\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-bkg_subtracted_event_rates.pdf\".format(save_fig_dir, var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfolding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closure test \n",
    "- use MC signal as fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "mc_stack, bins, _ = plt.hist(var_per_nuint_categ_mc,\n",
    "                            bins=bins,\n",
    "                            weights=weights_per_categ,\n",
    "                            stacked=True,\n",
    "                            color=colors,\n",
    "                            label=mode_labels,\n",
    "                            edgecolor='none',\n",
    "                            linewidth=0,\n",
    "                            density=False,\n",
    "                            histtype='stepfilled')\n",
    "\n",
    "totmc, bin_edges = np.histogram(var_total_mc, bins=bins, weights=mc_evt_df.pot_weight)\n",
    "bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "# use MC as fake data for closure test\n",
    "fake_data = totmc\n",
    "fake_data_err = np.sqrt(totmc)\n",
    "# plt.step(bin_edges[:-1], fake_data, where='post', label=\"Data\")  # line\n",
    "plt.errorbar(bin_centers, fake_data, yerr=fake_data_err, fmt='o', color='black')  # error bars\n",
    "\n",
    "accum_sum = [np.sum(data) for data in mc_stack]\n",
    "accum_sum = [0.] + accum_sum\n",
    "total_sum = accum_sum[-1]\n",
    "individual_sums = [accum_sum[i + 1] - accum_sum[i] for i in range(len(accum_sum) - 1)]\n",
    "fractions = [(count / total_sum) * 100 for count in individual_sums]\n",
    "legend_labels = [f\"{label} ({frac:.1f}%)\" for label, frac in zip(mode_labels[::-1], fractions[::-1])]\n",
    "legend_labels.append(\"Fake Data\")\n",
    "plt.legend(legend_labels, loc='upper left', fontsize=10, frameon=False, ncol=3, bbox_to_anchor=(0.05, 0.98))\n",
    "\n",
    "plt.xlim(bins[0], bins[-1])\n",
    "plt.xlabel(var_labels[1])\n",
    "plt.ylim(0., 1.2 * fake_data.max())\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-fake_data.pdf\".format(save_fig_dir, var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_type = 2\n",
    "Norm_type = 1\n",
    "Measured = reco_signal_sel * XSEC_UNIT # = fake_data - fake_background\n",
    "Model = true_signal*XSEC_UNIT\n",
    "unfold = WienerSVD(Response, Model, Measured, Covariance, C_type, Norm_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfold.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfold['unfold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfold['UnfoldCov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2(data, model, cov):\n",
    "    return (data - model) @ np.linalg.inv(cov) @ (data - model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfold['unfold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfold['AddSmear'] @ true_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unfold = unfold['unfold']\n",
    "UnfoldCov = unfold['UnfoldCov']\n",
    "Unfold_uncert = np.sqrt(np.diag(UnfoldCov))\n",
    "\n",
    "step_handle, = plt.step(bin_edges, np.append(Unfold, Unfold[-1]), where='post', label='Unfolded', color='black')\n",
    "bar_handle = plt.bar(\n",
    "    bin_centers,\n",
    "    2*Unfold_uncert,\n",
    "    width=(bin_edges[1] - bin_edges[0]) * 1.,\n",
    "    bottom=Unfold - Unfold_uncert,\n",
    "    color='gray',\n",
    "    alpha=0.5,\n",
    "    linewidth=0,\n",
    "    label='Unfolded Stat. error (box)'\n",
    ")\n",
    "reco_handle, = plt.plot(bin_centers, Measured, 'o', label='Reco. signal')\n",
    "Model_smear = unfold['AddSmear'] @ Model\n",
    "true_handle, = plt.plot(bin_centers, Model_smear, 'o', label='$A_c \\\\times$ True signal')\n",
    "\n",
    "chi2_val = chi2(Unfold, Model_smear, UnfoldCov)\n",
    "plt.text(0.95, 0.50, f\"$ \\\\chi^2 = $ {chi2_val:.2f}\", ha='right', va='center', \n",
    "         transform=plt.gca().transAxes, fontsize=12)\n",
    "\n",
    "# Custom order for legend\n",
    "handles = [step_handle, bar_handle, reco_handle, true_handle]\n",
    "labels = [\n",
    "    'Unfolded',\n",
    "    'Unfolded error',\n",
    "    'Reco. signal',\n",
    "    '$A_c \\\\times$True signal'\n",
    "]\n",
    "\n",
    "plt.legend(handles, labels)\n",
    "plt.xlim(bins[0], bins[-1])\n",
    "plt.xlabel(var_labels[0])\n",
    "# plt.ylim(0., 5000.)\n",
    "plt.ylabel(\"Events\")\n",
    "\n",
    "if save_fig:\n",
    "    plt.savefig(\"{}/{}-unfolded_event_rates.pdf\".format(save_fig_dir, var_save_name), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_name = \"{}/{}-{}-add_smear\".format(save_fig_dir, var_save_name, syst_name)\n",
    "plot_labels = [var_labels[2], var_labels[1]]\n",
    "plot_heatmap(unfold[\"AddSmear\"], \"$A_c$\", plot_labels=plot_labels,\n",
    "             save_fig=save_fig, save_fig_name=save_fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
