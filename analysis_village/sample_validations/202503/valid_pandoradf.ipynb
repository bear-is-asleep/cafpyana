{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import uproot as uproot\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib import ticker\n",
    "from matplotlib.ticker import (AutoMinorLocator, MultipleLocator)\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# Add the head direcoty to sys.path\n",
    "workspace_root = os.getcwd()  \n",
    "sys.path.insert(0, workspace_root + \"/../../../\")\n",
    "\n",
    "# import this repo's classes\n",
    "import pyanalib.pandas_helpers as ph\n",
    "from makedf.util import *\n",
    "\n",
    "import dunestyle.matplotlib as dunestyle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venv_path = os.getenv(\"PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"/exp/sbnd/data/users/sungbino/sbnd_samples/cafpyana_outputs/\"\n",
    "mc_file = input_path + \"Spring25Dev_MC_bnb_cosmics.df\"\n",
    "data_file = input_path + \"Spring25Dev_data.df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_hdr_df = pd.read_hdf(mc_file, key='hdr')\n",
    "mc_evt_df = pd.read_hdf(mc_file, key='evt')\n",
    "mc_nu_df = pd.read_hdf(mc_file, key='mcnu')\n",
    "\n",
    "data_hdr_df = pd.read_hdf(data_file, key='hdr')\n",
    "data_evt_df = pd.read_hdf(data_file, key='evt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_hdr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hdr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_tot_pot = mc_hdr_df['pot'].sum()\n",
    "data_tot_pot = data_hdr_df['pot'].sum()\n",
    "\n",
    "print(\"mc_tot_pot: %e, data_tot_pot: %e\" %(mc_tot_pot, data_tot_pot))\n",
    "#POT_scale = target_POT / this_pot\n",
    "#print(POT_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_nu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_nu_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_fv = InFV(mc_nu_df.position, 0, 0, 0, 0, \"SBND\")\n",
    "is_cc = mc_nu_df.iscc\n",
    "genie_mode = mc_nu_df.genie_mode\n",
    "nuint_categ = pd.Series(8, index=mc_nu_df.index)\n",
    "nuint_categ[~is_fv] = -1  # Out of FV\n",
    "nuint_categ[is_fv & ~is_cc] = 0  # NC\n",
    "nuint_categ[is_fv & is_cc & (genie_mode == 3)] = 1  # CCCOH\n",
    "nuint_categ[is_fv & is_cc & (genie_mode == 0)] = 2  # CCQE\n",
    "nuint_categ[is_fv & is_cc & (genie_mode == 10)] = 3  # 2p2h\n",
    "nuint_categ[is_fv & is_cc & (genie_mode != 0) & (genie_mode != 3) & (genie_mode != 10) & (genie_mode == 1)] = 4  # RES\n",
    "nuint_categ[is_fv & is_cc & (genie_mode != 0) & (genie_mode != 3) & (genie_mode != 10) & (genie_mode == 2)] = 5  # DIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_nu_df['nuint_categ'] = nuint_categ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_evt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = data_evt_df.slc.vertex.x \n",
    "plt.hist(var, bins=np.linspace(-210., 210., 43), weights=[np.ones_like(data) * 1. for data in var], histtype=\"step\", label=[\"all\"])\n",
    "plt.xlabel(\"Neutrino Energy (GeV)\")\n",
    "plt.ylabel(f\"Neutrinos (POT = {mc_tot_pot:.2e})\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_evt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True nu variables\n",
    "\n",
    "## 1) nu.E\n",
    "var = mc_nu_df.E \n",
    "plt.hist(var, bins=np.linspace(0., 8., 81), weights=[np.ones_like(data) * 1. for data in var], histtype=\"step\", label=[\"all\"])\n",
    "plt.xlabel(\"Neutrino Energy (GeV)\")\n",
    "plt.ylabel(f\"Neutrinos (POT = {mc_tot_pot:.2e})\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_matchdf = ph.multicol_merge(mc_evt_df.reset_index(), mc_nu_df.reset_index(),\n",
    "                            left_on=[(\"entry\", \"\",\"\"), (\"slc\",\"tmatch\", \"idx\", \"\", \"\", \"\")],\n",
    "                            right_on=[(\"entry\", \"\",\"\"), (\"rec.mc.nu..index\", \"\",\"\")], \n",
    "                            how=\"left\") ## -- save all sllices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_matchdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Make unmatched slice to have nuint_categ = -2\n",
    "notmatcheddf = mc_matchdf[pd.isna(mc_matchdf.nuint_categ)]\n",
    "matcheddf = mc_matchdf[~pd.isna(mc_matchdf.nuint_categ)]\n",
    "notmatcheddf.nuint_categ = -2\n",
    "mc_matchdf = pd.concat([matcheddf, notmatcheddf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_matchdf = mc_matchdf.set_index(['entry', 'rec.slc..index', 'rec.slc.reco.pfp..index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_matchdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- Label definitions for plotting\n",
    "mode_list = [1, 0, 4, 5, 3, 2, -1, -2]\n",
    "mode_labels = [\"CC COH\", \"NC\", \"CC RES\", \"CC IDS\", \"CC 2p2h\", \"CC QE\", \"Non-FV\", \"Others\"]\n",
    "colors = [#'#d62728',  # Red            \n",
    "          '#1f77b4',  # Blue\n",
    "          '#ff7f0e',  # Orange\n",
    "          '#2ca02c',  # Green\n",
    "          '#17becf',  # Teal\n",
    "          '#9467bd',  # Purple\n",
    "          '#8c564b',  # Brown\n",
    "          '#e377c2',  # Pink\n",
    "          '#7f7f7f']  # Gray\n",
    "          #'#bcbd22',  # Yellow-green\n",
    "          #'#17becf']  # Teal\n",
    "\n",
    "def draw_reco_stacked_hist(var, is_logy, title_x, title_y, x_min, x_max, nbins, outname, data_overlay = False, var_data = []):\n",
    "    plt.figure(figsize=(800/100, 600/100), dpi=100)\n",
    "    POT_scale = 1.\n",
    "    # No data overlay â€” keep original logic\n",
    "    hist_data, bins, _ = plt.hist(var,\n",
    "                                    bins=np.linspace(x_min, x_max, nbins + 1),\n",
    "                                    weights=[np.ones_like(data) * POT_scale for data in var],\n",
    "                                    stacked=True,\n",
    "                                    color=colors,\n",
    "                                    label=mode_labels,\n",
    "                                    edgecolor='none',\n",
    "                                    linewidth=0,\n",
    "                                    density=data_overlay,\n",
    "                                histtype='stepfilled')\n",
    "    max_y = np.max([np.sum(vals) for vals in zip(*hist_data)])\n",
    "    print(max_y)\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(0.0, max_y * 1.5)\n",
    "    plt.xlabel(title_x)\n",
    "    plt.ylabel(title_y)\n",
    "    if is_logy:\n",
    "        plt.ylim(0.1, max_y * 600)\n",
    "        plt.yscale('log')\n",
    "    \n",
    "    if data_overlay:\n",
    "        plt.ylabel(\"A.U.\")\n",
    "        # Normalize data by area\n",
    "        counts, _ = np.histogram(var_data, bins=np.linspace(x_min, x_max, nbins + 1))\n",
    "        bin_widths = np.diff(np.linspace(x_min, x_max, nbins + 1))\n",
    "        total_data = np.sum(counts)\n",
    "        norm_counts = counts / (total_data * bin_widths)\n",
    "        errors = np.sqrt(counts) / (total_data * bin_widths) if total_data > 0 else np.zeros_like(counts)\n",
    "        bin_centers = 0.5 * (np.linspace(x_min, x_max, nbins + 1)[:-1] + np.linspace(x_min, x_max, nbins + 1)[1:])\n",
    "\n",
    "        # -- non-zero mask\n",
    "        nonzero_mask = counts > 0\n",
    "        bin_centers = bin_centers[nonzero_mask]\n",
    "        norm_counts = norm_counts[nonzero_mask]\n",
    "        errors = errors[nonzero_mask]\n",
    "        \n",
    "        # Plot data with error bars\n",
    "        plt.errorbar(bin_centers, norm_counts, yerr=errors,\n",
    "                     fmt='o', color='black', label='Data',\n",
    "                     markersize=5, capsize=3, linewidth=1.5)\n",
    "\n",
    "\n",
    "    ax = plt.gca()\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(2)\n",
    "    ax.tick_params(width=2, length=10)\n",
    "\n",
    "    accum_sum = [np.sum(data) for data in hist_data]\n",
    "    accum_sum = [0.] + accum_sum\n",
    "    total_sum = accum_sum[-1]\n",
    "    print(total_sum)\n",
    "    individual_sums = [accum_sum[i+1] - accum_sum[i] for i in range(len(accum_sum) - 1)]\n",
    "    fractions = [(count / total_sum) * 100 for count in individual_sums]\n",
    "    legend_labels = [f\"{label} ({frac:.1f}%)\" for label, frac in zip(mode_labels[::-1], fractions[::-1])]\n",
    "    if data_overlay:\n",
    "        legend_labels.append(\"Data\")\n",
    "    colors_reversed = colors[::-1]  # Ensure colors match reversed labels\n",
    "    plt.legend(legend_labels, loc='upper left', fontsize=11, frameon=False, ncol=3, bbox_to_anchor=(0.05, 0.98))\n",
    "    \n",
    "    plt.text(0.00, 1.02, \"SBND Sample (2025A Dev.), Preliminary\", transform=plt.gca().transAxes,\n",
    "             fontsize = 14, fontweight = 'bold')\n",
    "    #plt.savefig(\"../output/plots/reco_slc/\" + outname + \".pdf\", format='pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_mc_data_shape_comp_per_slc(mc_df, data_df, column, x_title, y_title, x_min, x_max, n_bins, out_name):\n",
    "    nuint_categ_col = ('nuint_categ', '', '', '', '', '')\n",
    "    mc_df_per_slc = mc_df.groupby([('entry'), ('rec.slc..index')])[[column, nuint_categ_col]].first()\n",
    "    data_df_per_slc = data_df.groupby([('entry'), ('rec.slc..index')])[[column]].first()\n",
    "    var_mc = [mc_df_per_slc[mc_df_per_slc.nuint_categ == mode][column] for mode in mode_list]\n",
    "    var_data = data_df_per_slc[column]\n",
    "    draw_reco_stacked_hist(var_mc, False, x_title, y_title, x_min, x_max, n_bins, out_name, True, var_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_reco_valid_plots(mc_df, data_df, suffix):\n",
    "    ## draw 1) clear cosmic, 2) nu score, 3) vertex x,y and z\n",
    "    \n",
    "    ## -- 1) Clear cosmic\n",
    "    clear_cosmic_col = ('slc', 'is_clear_cosmic', '', '', '', '')\n",
    "    draw_mc_data_shape_comp_per_slc(mc_df, data_df, clear_cosmic_col, \"Is Clear Cosmic\", \"A.U.\", -0.5, 1.5, 2, suffix + \"_slc_is_clear_cosmic\")\n",
    "\n",
    "    ## -- 2) nu score\n",
    "    nu_score_col = ('slc', 'nu_score', '', '', '', '')\n",
    "    draw_mc_data_shape_comp_per_slc(mc_df, data_df, nu_score_col, \"Nu Score\", \"A.U.\", -1.1, 1.1, 44, suffix + \"_slc_nu_score\")\n",
    "\n",
    "    ## -- 3) vertex x,y,z\n",
    "    vtx_x_col = ('slc', 'vertex', 'x', '', '', '')\n",
    "    vtx_y_col = ('slc', 'vertex', 'y', '', '', '')\n",
    "    vtx_z_col = ('slc', 'vertex', 'z', '', '', '')\n",
    "    draw_mc_data_shape_comp_per_slc(mc_df, data_df, vtx_x_col, \"Slice Vertex X [cm]\", \"A.U.\", -300, 300, 100, suffix + \"_slc_vtx_x\")\n",
    "    draw_mc_data_shape_comp_per_slc(mc_df, data_df, vtx_y_col, \"Slice Vertex Y [cm]\", \"A.U.\", -300, 300, 100, suffix + \"_slc_vtx_y\")\n",
    "    draw_mc_data_shape_comp_per_slc(mc_df, data_df, vtx_z_col, \"Slice Vertex Z [cm]\", \"A.U.\", -100, 600, 100, suffix + \"_slc_vtx_z\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reco 1) Nocut\n",
    "draw_reco_valid_plots(mc_matchdf, data_evt_df, \"nocut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reco 2) FV cut\n",
    "is_fv_mc = InFV(mc_matchdf.slc.vertex, 0, 0, 0, 0, \"SBND\")\n",
    "is_fv_data = InFV(data_evt_df.slc.vertex, 0, 0, 0, 0, \"SBND\")\n",
    "\n",
    "mc_matchdf = mc_matchdf[is_fv_mc]\n",
    "data_evt_df = data_evt_df[is_fv_data]\n",
    "\n",
    "draw_reco_valid_plots(mc_matchdf, data_evt_df, \"nocut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reco 3) !is_clear_cosmic\n",
    "isnt_clear_cosmic_mc = (mc_matchdf.slc.is_clear_cosmic == 0)\n",
    "isnt_clear_cosmic_data = (data_evt_df.slc.is_clear_cosmic == 0)\n",
    "\n",
    "mc_matchdf = mc_matchdf[isnt_clear_cosmic_mc]\n",
    "data_evt_df = data_evt_df[isnt_clear_cosmic_data]\n",
    "\n",
    "draw_reco_valid_plots(mc_matchdf, data_evt_df, \"is_clear_cosmic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_pfptrk_vertex(df):\n",
    "    this_vertex_x = df[('slc', 'vertex', 'x', '', '', '')]\n",
    "    this_vertex_y = df[('slc', 'vertex', 'y', '', '', '')]\n",
    "    this_vertex_z = df[('slc', 'vertex', 'z', '', '', '')]\n",
    "\n",
    "    this_pfp_start_x = df[('pfp', 'trk', 'start', 'x', '', '')]\n",
    "    this_pfp_start_y = df[('pfp', 'trk', 'start', 'y', '', '')]\n",
    "    this_pfp_start_z = df[('pfp', 'trk', 'start', 'z', '', '')]\n",
    "\n",
    "    this_dist = np.sqrt(\n",
    "        (this_vertex_x - this_pfp_start_x) ** 2 +\n",
    "        (this_vertex_y - this_pfp_start_y) ** 2 +\n",
    "        (this_vertex_z - this_pfp_start_z) ** 2\n",
    "    )\n",
    "\n",
    "    return this_dist\n",
    "\n",
    "def add_pfp_len_cut_multi_col(df, len_cut = 4., vtx_dist_cut = 6., n_trk_len_col = 'n_trk_4cm', n_trk_dist_col = 'n_trk_vtx_dist_6cm'):\n",
    "    ## pfp trk len > 4 cm\n",
    "    cut_trk_len = df.pfp.trk.len > len_cut\n",
    "    n_trk_df = cut_trk_len.reset_index(name='len')\n",
    "    all_combinations = (\n",
    "        n_trk_df[['entry', 'rec.slc..index']].drop_duplicates().set_index(['entry', 'rec.slc..index'])\n",
    "    )\n",
    "    n_trk_df = (\n",
    "        n_trk_df[n_trk_df['len'] == True]\n",
    "        .groupby(['entry', 'rec.slc..index'])\n",
    "        .size()\n",
    "        .reindex(all_combinations.index, fill_value=0)\n",
    "    )\n",
    "    df[('rec', n_trk_len_col, '', '', '', '')] = n_trk_df\n",
    "\n",
    "\n",
    "    ## and pfp trk vtx dist < 6 cm\n",
    "    vtx_dist_df_series = dist_pfptrk_vertex(df)\n",
    "    cut_vtx_dist = vtx_dist_df_series < vtx_dist_cut\n",
    "    cut_vtx_dist = cut_vtx_dist & cut_trk_len\n",
    "    n_vtx_dist_df = cut_vtx_dist.reset_index(name='len')\n",
    "\n",
    "    all_combinations = (\n",
    "        n_vtx_dist_df[['entry', 'rec.slc..index']].drop_duplicates().set_index(['entry', 'rec.slc..index'])\n",
    "    )\n",
    "    n_vtx_dist_df = (\n",
    "        n_vtx_dist_df[n_vtx_dist_df['len'] == True]\n",
    "        .groupby(['entry', 'rec.slc..index'])\n",
    "        .size()\n",
    "        .reindex(all_combinations.index, fill_value=0)\n",
    "    )\n",
    "    df[('rec', n_trk_dist_col, '', '', '', '')] = n_vtx_dist_df\n",
    "    df[('pfp', 'trk', 'pass_vtx_dist', '', '', '')] = cut_vtx_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_pfp_len_cut_multi_col(data_evt_df)\n",
    "add_pfp_len_cut_multi_col(mc_matchdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reco 4) n(pfp track with len > 4cm) = 2 \n",
    "n_pfp_trk_4cm_cut_mc = (mc_matchdf.rec.n_trk_4cm > 1)\n",
    "n_pfp_trk_4cm_cut_data = (data_evt_df.rec.n_trk_4cm > 1)\n",
    "\n",
    "mc_matchdf = mc_matchdf[n_pfp_trk_4cm_cut_mc]\n",
    "data_evt_df = data_evt_df[n_pfp_trk_4cm_cut_data]\n",
    "\n",
    "draw_reco_valid_plots(mc_matchdf, data_evt_df, \"n_pfp_trk_4cm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reco 5) n(pfp track with len > 4cm && vtx dist < 6 cm) = 2 \n",
    "n_trk_vtx_dist_6cm_cut_mc = (mc_matchdf.rec.n_trk_vtx_dist_6cm == 2)\n",
    "n_trk_vtx_dist_6cm_cut_data = (data_evt_df.rec.n_trk_vtx_dist_6cm == 2)\n",
    "\n",
    "mc_matchdf = mc_matchdf[n_trk_vtx_dist_6cm_cut_mc]\n",
    "data_evt_df = data_evt_df[n_trk_vtx_dist_6cm_cut_data]\n",
    "\n",
    "draw_reco_valid_plots(mc_matchdf, data_evt_df, \"n_pfp_trk_4cm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_evt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opening_angle(n_trk_vtx_dist, dir_x, dir_y, dir_z, trk_vtx_dist_pass):\n",
    "    #print(\"opening_angle\")                                                                                                                                                                                                                                                     \n",
    "    if n_trk_vtx_dist != 2:\n",
    "        return -999.\n",
    "    dir_x = dir_x[trk_vtx_dist_pass]\n",
    "    dir_y = dir_y[trk_vtx_dist_pass]\n",
    "    dir_z = dir_z[trk_vtx_dist_pass]\n",
    "    if(dir_x.size != 2):\n",
    "        print(\"error, dir_x.len != 2\")\n",
    "        return -888.\n",
    "\n",
    "    this_cos_theta = dir_x.iloc[0] * dir_x.iloc[1] + dir_y.iloc[0] * dir_y.iloc[1] + dir_z.iloc[0] * dir_z.iloc[1]\n",
    "    return this_cos_theta\n",
    "\n",
    "def measure_opening_angle(group):\n",
    "    n_trk_vtx_dist = group[('rec', 'n_trk_vtx_dist_6cm', '', '', '', '')].iloc[0]\n",
    "    dir_x = group[('pfp', 'trk', 'dir', 'x', '', '')]\n",
    "    dir_y = group[('pfp', 'trk', 'dir', 'y', '', '')]\n",
    "    dir_z = group[('pfp', 'trk', 'dir', 'z', '', '')]\n",
    "    trk_vtx_dist_pass = group[('pfp', 'trk', 'pass_vtx_dist', '', '', '')]\n",
    "\n",
    "    # Call reco_t function                                                                                                                                                                                                                                                      \n",
    "    return opening_angle(n_trk_vtx_dist, dir_x, dir_y, dir_z, trk_vtx_dist_pass)\n",
    "\n",
    "def add_two_trk_opening_angle_col(df):\n",
    "    opening_angle_series = df.groupby(['entry', 'rec.slc..index']).apply(measure_opening_angle)\n",
    "    opening_angle_df = opening_angle_series.to_frame(name='reco_opening_angle')\n",
    "    opening_angle_df.index.set_names(['entry', 'rec.slc..index'], inplace=True)\n",
    "    df[('rec', 'opening_angle', '', '', '', '')] = opening_angle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_two_trk_opening_angle_col(data_evt_df)\n",
    "add_two_trk_opening_angle_col(mc_matchdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_evt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_matchdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opening_ang_col = ('rec', 'opening_angle', '', '', '', '')\n",
    "draw_mc_data_shape_comp_per_slc(mc_matchdf, data_evt_df, opening_ang_col, \"cos(open ang)\", \"A.U.\", -1, 1, 100, \"_opening_ang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reco 6) two track opening angle > -0.75\n",
    "open_ang_cut_mc = (mc_matchdf.rec.opening_angle > -0.75)\n",
    "open_ang_cut_data = (data_evt_df.rec.opening_angle > -0.75)\n",
    "\n",
    "mc_matchdf = mc_matchdf[open_ang_cut_mc]\n",
    "data_evt_df = data_evt_df[open_ang_cut_data]\n",
    "\n",
    "draw_reco_valid_plots(mc_matchdf, data_evt_df, \"open_angle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_mc_data_shape_comp_per_slc(mc_matchdf, data_evt_df, opening_ang_col, \"cos(open ang)\", \"A.U.\", -1, 1, 100, \"_opening_ang\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_py39_cafpyana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
